{"version":3,"file":"model-meta-qwen.js","sources":["../../../src/meta/model-meta-qwen.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst QWEN_LATEST = {\n  name: 'qwen:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '2.3gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_0_5b = {\n  name: 'qwen:0.5b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '395mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_1_8b = {\n  name: 'qwen:1.8b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '1.1gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_4b = {\n  name: 'qwen:4b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '2.3gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_7b = {\n  name: 'qwen:7b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '4.5gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_14b = {\n  name: 'qwen:14b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '8.2gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_32b = {\n  name: 'qwen:32b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '18gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_72b = {\n  name: 'qwen:72b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '41gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst QWEN_110b = {\n  name: 'qwen:110b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '63gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nexport const QWEN_MODELS = [\n  QWEN_LATEST.name,\n  QWEN_0_5b.name,\n  QWEN_1_8b.name,\n  QWEN_4b.name,\n  QWEN_7b.name,\n  QWEN_14b.name,\n  QWEN_32b.name,\n  QWEN_72b.name,\n  QWEN_110b.name,\n] as const\n\n// const QWEN_IMAGE_MODELS = [] as const\n\n// export const QWEN_EMBEDDING_MODELS = [] as const\n\n// const QWEN_AUDIO_MODELS = [] as const\n\n// const QWEN_VIDEO_MODELS = [] as const\n\n// export type QwenChatModels = (typeof QWEN_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type QwenChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [QWEN_LATEST.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_0_5b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_1_8b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_4b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_7b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_14b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_32b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_72b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [QWEN_110b.name]: OllamaChatRequest & OllamaChatRequestMessages\n}\n\nexport type QwenModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [QWEN_LATEST.name]: typeof QWEN_LATEST.supports.input\n  [QWEN_0_5b.name]: typeof QWEN_0_5b.supports.input\n  [QWEN_1_8b.name]: typeof QWEN_1_8b.supports.input\n  [QWEN_4b.name]: typeof QWEN_4b.supports.input\n  [QWEN_7b.name]: typeof QWEN_7b.supports.input\n  [QWEN_14b.name]: typeof QWEN_14b.supports.input\n  [QWEN_32b.name]: typeof QWEN_32b.supports.input\n  [QWEN_72b.name]: typeof QWEN_72b.supports.input\n  [QWEN_110b.name]: typeof QWEN_110b.supports.input\n}\n"],"names":[],"mappings":"AAMA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIA,MAAM,UAAU;AAAA,EACd,MAAM;AAQR;AAIA,MAAM,UAAU;AAAA,EACd,MAAM;AAQR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIO,MAAM,cAAc;AAAA,EACzB,YAAY;AAAA,EACZ,UAAU;AAAA,EACV,UAAU;AAAA,EACV,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,SAAS;AAAA,EACT,SAAS;AAAA,EACT,SAAS;AAAA,EACT,UAAU;AACZ;"}