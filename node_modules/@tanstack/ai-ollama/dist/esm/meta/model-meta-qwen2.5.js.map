{"version":3,"file":"model-meta-qwen2.5.js","sources":["../../../src/meta/model-meta-qwen2.5.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaChatRequestTools,\n  OllamaMessageTools,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst QWEN2_5_LATEST = {\n  name: 'qwen2.5:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.7gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_0_5b = {\n  name: 'qwen2.5:0.5b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '398mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_1_5b = {\n  name: 'qwen2.5:1.5b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '986mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_3b = {\n  name: 'qwen2.5:3b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '1.9gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_7b = {\n  name: 'qwen2.5:7b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.7gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_14b = {\n  name: 'qwen2.5:14b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '9gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_32b = {\n  name: 'qwen2.5:32b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '20gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_5_72b = {\n  name: 'qwen2.5:72b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '47gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nexport const QWEN2_5_MODELS = [\n  QWEN2_5_LATEST.name,\n  QWEN2_5_0_5b.name,\n  QWEN2_5_1_5b.name,\n  QWEN2_5_3b.name,\n  QWEN2_5_7b.name,\n  QWEN2_5_32b.name,\n  QWEN2_5_72b.name,\n] as const\n\n// const QWEN2_5_IMAGE_MODELS = [] as const\n\n// export const QWEN2_5_EMBEDDING_MODELS = [] as const\n\n// const QWEN2_5_AUDIO_MODELS = [] as const\n\n// const QWEN2_5_VIDEO_MODELS = [] as const\n\n// export type Qwen2_5ChatModels = (typeof QWEN2_5_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Qwen2_5ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [QWEN2_5_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_0_5b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_1_5b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_3b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_7b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_14b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_32b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_5_72b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n}\n\nexport type Qwen2_5ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [QWEN2_5_LATEST.name]: typeof QWEN2_5_LATEST.supports.input\n  [QWEN2_5_0_5b.name]: typeof QWEN2_5_0_5b.supports.input\n  [QWEN2_5_1_5b.name]: typeof QWEN2_5_1_5b.supports.input\n  [QWEN2_5_3b.name]: typeof QWEN2_5_3b.supports.input\n  [QWEN2_5_7b.name]: typeof QWEN2_5_7b.supports.input\n  [QWEN2_5_14b.name]: typeof QWEN2_5_7b.supports.input\n  [QWEN2_5_32b.name]: typeof QWEN2_5_32b.supports.input\n  [QWEN2_5_72b.name]: typeof QWEN2_5_72b.supports.input\n}\n"],"names":[],"mappings":"AAQA,MAAM,iBAAiB;AAAA,EACrB,MAAM;AAQR;AAMA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAMA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAMA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAMA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAqBA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAMA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAMO,MAAM,iBAAiB;AAAA,EAC5B,eAAe;AAAA,EACf,aAAa;AAAA,EACb,aAAa;AAAA,EACb,WAAW;AAAA,EACX,WAAW;AAAA,EACX,YAAY;AAAA,EACZ,YAAY;AACd;"}