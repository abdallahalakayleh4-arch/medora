{"version":3,"file":"model-meta-llama3.1.js","sources":["../../../src/meta/model-meta-llama3.1.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaChatRequestTools,\n  OllamaMessageTools,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst LLAMA3_1_LATEST = {\n  name: 'llama3.1:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.9gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst LLAMA3_1_8b = {\n  name: 'llama3.1:8b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.9gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst LLAMA3_1_70b = {\n  name: 'llama3.1:70b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '43gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst LLAMA3_1_405b = {\n  name: 'llama3.1:405b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '243gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nexport const LLAMA3_1_MODELS = [\n  LLAMA3_1_LATEST.name,\n  LLAMA3_1_8b.name,\n  LLAMA3_1_70b.name,\n  LLAMA3_1_405b.name,\n] as const\n\n// const LLAMA3_1_IMAGE_MODELS = [] as const\n\n// export const LLAMA3_1_EMBEDDING_MODELS = [] as const\n\n// const LLAMA3_1_AUDIO_MODELS = [] as const\n\n// const LLAMA3_1_VIDEO_MODELS = [] as const\n\n// export type Llama3_1ChatModels = (typeof LLAMA3_1_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Llama3_1ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [LLAMA3_1_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [LLAMA3_1_8b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [LLAMA3_1_70b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [LLAMA3_1_405b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n}\n\nexport type Llama3_1ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [LLAMA3_1_LATEST.name]: typeof LLAMA3_1_LATEST.supports.input\n  [LLAMA3_1_8b.name]: typeof LLAMA3_1_8b.supports.input\n  [LLAMA3_1_70b.name]: typeof LLAMA3_1_70b.supports.input\n  [LLAMA3_1_405b.name]: typeof LLAMA3_1_405b.supports.input\n}\n"],"names":[],"mappings":"AAQA,MAAM,kBAAkB;AAAA,EACtB,MAAM;AAQR;AAMA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAMA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAMA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAQR;AAMO,MAAM,kBAAkB;AAAA,EAC7B,gBAAgB;AAAA,EAChB,YAAY;AAAA,EACZ,aAAa;AAAA,EACb,cAAc;AAChB;"}