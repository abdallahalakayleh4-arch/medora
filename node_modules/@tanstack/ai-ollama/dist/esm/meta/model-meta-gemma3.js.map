{"version":3,"file":"model-meta-gemma3.js","sources":["../../../src/meta/model-meta-gemma3.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaMessageImages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst GEMMA3_LATEST = {\n  name: 'gemma3:latest',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '3.3gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst GEMMA3_270m = {\n  name: 'gemma3:270m',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '298mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst GEMMA3_1b = {\n  name: 'gemma3:1b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '815mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst GEMMA3_4b = {\n  name: 'gemma3:4b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '3.3gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst GEMMA3_12b = {\n  name: 'gemma3:12b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '8.1gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst GEMMA3_27b = {\n  name: 'gemma3:27b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '17gb',\n  context: 128_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nexport const GEMMA3_MODELS = [\n  GEMMA3_LATEST.name,\n  GEMMA3_270m.name,\n  GEMMA3_1b.name,\n  GEMMA3_4b.name,\n  GEMMA3_12b.name,\n  GEMMA3_27b.name,\n] as const\n\n// const GEMMA3_IMAGE_MODELS = [] as const\n\n// export const GEMMA3_EMBEDDING_MODELS = [] as const\n\n// const GEMMA3_AUDIO_MODELS = [] as const\n\n// const GEMMA3_VIDEO_MODELS = [] as const\n\n// export type Gemma3ChatModels = (typeof GEMMA3_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Gemma3ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [GEMMA3_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n  [GEMMA3_270m.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n  [GEMMA3_1b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n  [GEMMA3_4b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n  [GEMMA3_12b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n  [GEMMA3_27b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n}\n\nexport type Gemma3ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [GEMMA3_LATEST.name]: typeof GEMMA3_LATEST.supports.input\n  [GEMMA3_270m.name]: typeof GEMMA3_270m.supports.input\n  [GEMMA3_1b.name]: typeof GEMMA3_1b.supports.input\n  [GEMMA3_4b.name]: typeof GEMMA3_4b.supports.input\n  [GEMMA3_12b.name]: typeof GEMMA3_12b.supports.input\n  [GEMMA3_27b.name]: typeof GEMMA3_27b.supports.input\n}\n"],"names":[],"mappings":"AAOA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAQR;AAIA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAIA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAIO,MAAM,gBAAgB;AAAA,EAC3B,cAAc;AAAA,EACd,YAAY;AAAA,EACZ,UAAU;AAAA,EACV,UAAU;AAAA,EACV,WAAW;AAAA,EACX,WAAW;AACb;"}