{"version":3,"file":"model-meta-llava.js","sources":["../../../src/meta/model-meta-llava.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaMessageImages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst LLAVA_LATEST = {\n  name: 'llava:latest',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: ['vision'],\n  },\n  size: '4.7gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst LLAVA_7b = {\n  name: 'llava:7b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: ['vision'],\n  },\n  size: '4.7gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst LLAVA_13b = {\n  name: 'llava:13b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: ['vision'],\n  },\n  size: '8gb',\n  context: 4_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nconst LLAVA_34b = {\n  name: 'llava:34b',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    capabilities: ['vision'],\n  },\n  size: '20gb',\n  context: 4_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages<OllamaMessageImages>\n>\n\nexport const LLAVA_MODELS = [\n  LLAVA_LATEST.name,\n  LLAVA_7b.name,\n  LLAVA_13b.name,\n  LLAVA_34b.name,\n] as const\n\n// const LLAVA_IMAGE_MODELS = [] as const\n\n// export const LLAVA_EMBEDDING_MODELS = [] as const\n\n// const LLAVA_AUDIO_MODELS = [] as const\n\n// const LLAVA_VIDEO_MODELS = [] as const\n\n// export type LlavaChatModels = (typeof LLAVA_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type LlavaChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [LLAVA_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n\n  [LLAVA_7b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n\n  [LLAVA_13b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n\n  [LLAVA_34b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageImages>\n}\n\nexport type LlavaModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [LLAVA_LATEST.name]: typeof LLAVA_LATEST.supports.input\n  [LLAVA_7b.name]: typeof LLAVA_7b.supports.input\n  [LLAVA_13b.name]: typeof LLAVA_13b.supports.input\n  [LLAVA_34b.name]: typeof LLAVA_34b.supports.input\n}\n"],"names":[],"mappings":"AAOA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAIO,MAAM,eAAe;AAAA,EAC1B,aAAa;AAAA,EACb,SAAS;AAAA,EACT,UAAU;AAAA,EACV,UAAU;AACZ;"}