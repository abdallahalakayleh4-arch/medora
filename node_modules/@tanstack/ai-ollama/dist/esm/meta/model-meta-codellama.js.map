{"version":3,"file":"model-meta-codellama.js","sources":["../../../src/meta/model-meta-codellama.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst CODELLAMA_LATEST = {\n  name: 'codellama:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '3.8gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst CODELLAMA_7b = {\n  name: 'codellama:7b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '3.8gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst CODELLAMA_13b = {\n  name: 'codellama:13b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '7.4gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst CODELLAMA_34b = {\n  name: 'codellama:34b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '19gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst CODELLAMA_70b = {\n  name: 'codellama:70b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '39gb',\n  context: 2_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nexport const CODELLAMA_MODELS = [\n  CODELLAMA_LATEST.name,\n  CODELLAMA_7b.name,\n  CODELLAMA_13b.name,\n  CODELLAMA_34b.name,\n  CODELLAMA_70b.name,\n] as const\n\n// const CODELLAMA_IMAGE_MODELS = [] as const\n\n// export const CODELLAMA_EMBEDDING_MODELS = [] as const\n\n// const CODELLAMA_AUDIO_MODELS = [] as const\n\n// const CODELLAMA_VIDEO_MODELS = [] as const\n\n// export type CodellamaChatModels = (typeof CODELLAMA_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type CodellamaChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [CODELLAMA_LATEST.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [CODELLAMA_7b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [CODELLAMA_13b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [CODELLAMA_34b.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [CODELLAMA_70b.name]: OllamaChatRequest & OllamaChatRequestMessages\n}\n\nexport type CodellamaModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [CODELLAMA_LATEST.name]: typeof CODELLAMA_LATEST.supports.input\n  [CODELLAMA_7b.name]: typeof CODELLAMA_7b.supports.input\n  [CODELLAMA_13b.name]: typeof CODELLAMA_13b.supports.input\n  [CODELLAMA_34b.name]: typeof CODELLAMA_34b.supports.input\n  [CODELLAMA_70b.name]: typeof CODELLAMA_70b.supports.input\n}\n"],"names":[],"mappings":"AAMA,MAAM,mBAAmB;AAAA,EACvB,MAAM;AAQR;AAIA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAIA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAQR;AAIA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAQR;AAIA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAQR;AAIO,MAAM,mBAAmB;AAAA,EAC9B,iBAAiB;AAAA,EACjB,aAAa;AAAA,EACb,cAAc;AAAA,EACd,cAAc;AAAA,EACd,cAAc;AAChB;"}