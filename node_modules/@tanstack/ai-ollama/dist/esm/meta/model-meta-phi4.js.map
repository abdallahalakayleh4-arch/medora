{"version":3,"file":"model-meta-phi4.js","sources":["../../../src/meta/model-meta-phi4.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst PHI4_LATEST = {\n  name: 'phi4:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '9.1gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst PHI4_14b = {\n  name: 'phi4:14b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '9.1gb',\n  context: 16_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nexport const PHI4_MODELS = [PHI4_LATEST.name, PHI4_14b.name] as const\n\n// const PHI4_IMAGE_MODELS = [] as const\n\n// export const PHI4_EMBEDDING_MODELS = [] as const\n\n// const PHI4_AUDIO_MODELS = [] as const\n\n// const PHI4_VIDEO_MODELS = [] as const\n\n// export type Phi4ChatModels = (typeof PHI4_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Phi4ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [PHI4_LATEST.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [PHI4_14b.name]: OllamaChatRequest & OllamaChatRequestMessages\n}\n\nexport type Phi4ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [PHI4_LATEST.name]: typeof PHI4_LATEST.supports.input\n  [PHI4_14b.name]: typeof PHI4_14b.supports.input\n}\n"],"names":[],"mappings":"AAMA,MAAM,cAAc;AAAA,EAClB,MAAM;AAQR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAIO,MAAM,cAAc,CAAC,YAAY,MAAM,SAAS,IAAI;"}