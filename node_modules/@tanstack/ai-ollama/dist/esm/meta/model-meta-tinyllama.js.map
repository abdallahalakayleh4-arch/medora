{"version":3,"file":"model-meta-tinyllama.js","sources":["../../../src/meta/model-meta-tinyllama.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst TINYLLAMA_LATEST = {\n  name: 'tinyllama:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '638mb',\n  context: 2_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nconst TINYLLAMA_1_1b = {\n  name: 'tinyllama:1.1b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: [],\n  },\n  size: '638mb',\n  context: 2_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest & OllamaChatRequestMessages\n>\n\nexport const TINYLLAMA_MODELS = [\n  TINYLLAMA_LATEST.name,\n  TINYLLAMA_1_1b.name,\n] as const\n\n// const TINYLLAMA_IMAGE_MODELS = [] as const\n\n// export const TINYLLAMA_EMBEDDING_MODELS = [] as const\n\n// const TINYLLAMA_AUDIO_MODELS = [] as const\n\n// const TINYLLAMA_VIDEO_MODELS = [] as const\n\n// export type TinyllamaChatModels = (typeof TINYLLAMA_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type TinyllamaChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [TINYLLAMA_LATEST.name]: OllamaChatRequest & OllamaChatRequestMessages\n  [TINYLLAMA_1_1b.name]: OllamaChatRequest & OllamaChatRequestMessages\n}\n\nexport type TinyllamaModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [TINYLLAMA_LATEST.name]: typeof TINYLLAMA_LATEST.supports.input\n  [TINYLLAMA_1_1b.name]: typeof TINYLLAMA_1_1b.supports.input\n}\n"],"names":[],"mappings":"AAMA,MAAM,mBAAmB;AAAA,EACvB,MAAM;AAQR;AAIA,MAAM,iBAAiB;AAAA,EACrB,MAAM;AAQR;AAIO,MAAM,mBAAmB;AAAA,EAC9B,iBAAiB;AAAA,EACjB,eAAe;AACjB;"}