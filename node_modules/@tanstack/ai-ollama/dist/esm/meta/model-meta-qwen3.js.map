{"version":3,"file":"model-meta-qwen3.js","sources":["../../../src/meta/model-meta-qwen3.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaChatRequestThinking,\n  OllamaChatRequestTools,\n  OllamaMessageThinking,\n  OllamaMessageTools,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst QWEN3_LATEST = {\n  name: 'qwen3:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '5.2gb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_0_6b = {\n  name: 'qwen3:0.6b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '523mb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_1_7b = {\n  name: 'qwen3:1.7b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '1.4gb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_4b = {\n  name: 'qwen3:4b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '2.5gb',\n  context: 256_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_8b = {\n  name: 'qwen3:8b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '5.2gb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_14b = {\n  name: 'qwen3:14b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '9.3gb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_30b = {\n  name: 'qwen3:30b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '19gb',\n  context: 256_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_32b = {\n  name: 'qwen3:32b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '20gb',\n  context: 40_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nconst QWEN3_235b = {\n  name: 'qwen3:235b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['thinking', 'tools'],\n  },\n  size: '142gb',\n  context: 256_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n>\n\nexport const QWEN3_MODELS = [\n  QWEN3_LATEST.name,\n  QWEN3_0_6b.name,\n  QWEN3_1_7b.name,\n  QWEN3_4b.name,\n  QWEN3_8b.name,\n  QWEN3_14b.name,\n  QWEN3_30b.name,\n  QWEN3_32b.name,\n  QWEN3_235b.name,\n] as const\n\n// const QWEN3_IMAGE_MODELS = [] as const\n\n// export const QWEN3_EMBEDDING_MODELS = [] as const\n\n// const QWEN3_AUDIO_MODELS = [] as const\n\n// const QWEN3_VIDEO_MODELS = [] as const\n\n// export type Qwen3ChatModels = (typeof QWEN3_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Qwen3ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [QWEN3_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_0_6b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_1_7b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_4b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_8b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_14b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_30b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_32b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n  [QWEN3_235b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools & OllamaMessageThinking> &\n    OllamaChatRequestTools &\n    OllamaChatRequestThinking\n}\n\nexport type Qwen3ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [QWEN3_LATEST.name]: typeof QWEN3_LATEST.supports.input\n  [QWEN3_0_6b.name]: typeof QWEN3_0_6b.supports.input\n  [QWEN3_1_7b.name]: typeof QWEN3_1_7b.supports.input\n  [QWEN3_4b.name]: typeof QWEN3_4b.supports.input\n  [QWEN3_8b.name]: typeof QWEN3_8b.supports.input\n  [QWEN3_14b.name]: typeof QWEN3_14b.supports.input\n  [QWEN3_30b.name]: typeof QWEN3_30b.supports.input\n  [QWEN3_32b.name]: typeof QWEN3_32b.supports.input\n  [QWEN3_235b.name]: typeof QWEN3_235b.supports.input\n}\n"],"names":[],"mappings":"AAUA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAOA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAOA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAOA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAOA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAOA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAOA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAOA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAOA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAOO,MAAM,eAAe;AAAA,EAC1B,aAAa;AAAA,EACb,WAAW;AAAA,EACX,WAAW;AAAA,EACX,SAAS;AAAA,EACT,SAAS;AAAA,EACT,UAAU;AAAA,EACV,UAAU;AAAA,EACV,UAAU;AAAA,EACV,WAAW;AACb;"}