{"version":3,"file":"model-meta-qwen2.js","sources":["../../../src/meta/model-meta-qwen2.ts"],"sourcesContent":["import type {\n  OllamaChatRequest,\n  OllamaChatRequestMessages,\n  OllamaChatRequestTools,\n  OllamaMessageTools,\n  OllamaModelMeta,\n} from './models-meta'\n\nconst QWEN2_LATEST = {\n  name: 'qwen2:latest',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.4gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_0_5b = {\n  name: 'qwen2:0.5b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '352mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_1_5b = {\n  name: 'qwen2:1.5b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '935mb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_7b = {\n  name: 'qwen2:7b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '4.4gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nconst QWEN2_72b = {\n  name: 'qwen2:72b',\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    capabilities: ['tools'],\n  },\n  size: '41gb',\n  context: 32_000,\n} as const satisfies OllamaModelMeta<\n  OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n>\n\nexport const QWEN2_MODELS = [\n  QWEN2_LATEST.name,\n  QWEN2_0_5b.name,\n  QWEN2_1_5b.name,\n  QWEN2_7b.name,\n  QWEN2_72b.name,\n] as const\n\n// const QWEN2_IMAGE_MODELS = [] as const\n\n// export const QWEN2_EMBEDDING_MODELS = [] as const\n\n// const QWEN2_AUDIO_MODELS = [] as const\n\n// const QWEN2_VIDEO_MODELS = [] as const\n\n// export type Qwen2ChatModels = (typeof QWEN2_MODELS)[number]\n\n// Manual type map for per-model provider options\nexport type Qwen2ChatModelProviderOptionsByName = {\n  // Models with thinking and structured output support\n  [QWEN2_LATEST.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_0_5b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_1_5b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_7b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n  [QWEN2_72b.name]: OllamaChatRequest &\n    OllamaChatRequestMessages<OllamaMessageTools> &\n    OllamaChatRequestTools\n}\n\nexport type Qwen2ModelInputModalitiesByName = {\n  // Models with text, image, audio, video (no document)\n  [QWEN2_LATEST.name]: typeof QWEN2_LATEST.supports.input\n  [QWEN2_0_5b.name]: typeof QWEN2_0_5b.supports.input\n  [QWEN2_1_5b.name]: typeof QWEN2_1_5b.supports.input\n  [QWEN2_7b.name]: typeof QWEN2_7b.supports.input\n  [QWEN2_72b.name]: typeof QWEN2_72b.supports.input\n}\n"],"names":[],"mappings":"AAQA,MAAM,eAAe;AAAA,EACnB,MAAM;AAQR;AAMA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAMA,MAAM,aAAa;AAAA,EACjB,MAAM;AAQR;AAMA,MAAM,WAAW;AAAA,EACf,MAAM;AAQR;AAMA,MAAM,YAAY;AAAA,EAChB,MAAM;AAQR;AAMO,MAAM,eAAe;AAAA,EAC1B,aAAa;AAAA,EACb,WAAW;AAAA,EACX,WAAW;AAAA,EACX,SAAS;AAAA,EACT,UAAU;AACZ;"}