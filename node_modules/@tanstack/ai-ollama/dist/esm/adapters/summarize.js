import { createOllamaClient, estimateTokens, generateId, getOllamaHostFromEnv } from "../utils/client.js";
class OllamaSummarizeAdapter {
  constructor(hostOrClient, model, _options = {}) {
    this.kind = "summarize";
    this.name = "ollama";
    if (typeof hostOrClient === "string" || hostOrClient === void 0) {
      this.client = createOllamaClient({ host: hostOrClient });
    } else {
      this.client = hostOrClient;
    }
    this.model = model;
  }
  async summarize(options) {
    const model = options.model;
    const prompt = this.buildSummarizationPrompt(options);
    const response = await this.client.generate({
      model,
      prompt,
      options: {
        temperature: 0.3,
        num_predict: options.maxLength ?? 500
      },
      stream: false
    });
    const promptTokens = estimateTokens(prompt);
    const completionTokens = estimateTokens(response.response);
    return {
      id: generateId("sum"),
      model: response.model,
      summary: response.response,
      usage: {
        promptTokens,
        completionTokens,
        totalTokens: promptTokens + completionTokens
      }
    };
  }
  async *summarizeStream(options) {
    const model = options.model;
    const id = generateId("sum");
    const prompt = this.buildSummarizationPrompt(options);
    let accumulatedContent = "";
    const stream = await this.client.generate({
      model,
      prompt,
      options: {
        temperature: 0.3,
        num_predict: options.maxLength ?? 500
      },
      stream: true
    });
    for await (const chunk of stream) {
      if (chunk.response) {
        accumulatedContent += chunk.response;
        yield {
          type: "TEXT_MESSAGE_CONTENT",
          messageId: id,
          model: chunk.model,
          timestamp: Date.now(),
          delta: chunk.response,
          content: accumulatedContent
        };
      }
      if (chunk.done) {
        const promptTokens = estimateTokens(prompt);
        const completionTokens = estimateTokens(accumulatedContent);
        yield {
          type: "RUN_FINISHED",
          runId: id,
          model: chunk.model,
          timestamp: Date.now(),
          finishReason: "stop",
          usage: {
            promptTokens,
            completionTokens,
            totalTokens: promptTokens + completionTokens
          }
        };
      }
    }
  }
  buildSummarizationPrompt(options) {
    let prompt = "You are a professional summarizer. ";
    switch (options.style) {
      case "bullet-points":
        prompt += "Provide a summary in bullet point format. ";
        break;
      case "concise":
        prompt += "Provide a very brief one or two sentence summary. ";
        break;
      case "paragraph":
      default:
        prompt += "Provide a clear and concise summary in paragraph format. ";
    }
    if (options.maxLength) {
      prompt += `Keep the summary under ${options.maxLength} words. `;
    }
    if (options.focus && options.focus.length > 0) {
      prompt += `Focus on: ${options.focus.join(", ")}. `;
    }
    prompt += `

Text to summarize:
${options.text}

Summary:`;
    return prompt;
  }
}
function createOllamaSummarize(model, host, options) {
  return new OllamaSummarizeAdapter(host, model, options);
}
function ollamaSummarize(model, options) {
  const host = getOllamaHostFromEnv();
  return new OllamaSummarizeAdapter(host, model, options);
}
export {
  OllamaSummarizeAdapter,
  createOllamaSummarize,
  ollamaSummarize
};
//# sourceMappingURL=summarize.js.map
