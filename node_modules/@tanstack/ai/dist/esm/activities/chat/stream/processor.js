import { generateMessageId, uiMessageToModelMessages } from "../messages.js";
import { defaultJSONParser } from "./json-parser.js";
import { updateToolCallWithOutput, updateToolResultPart, updateToolCallApprovalResponse, updateToolCallPart, updateThinkingPart, updateToolCallApproval, updateTextPart } from "./message-updaters.js";
import { ImmediateStrategy } from "./strategies.js";
class StreamProcessor {
  constructor(options = {}) {
    this.messages = [];
    this.currentAssistantMessageId = null;
    this.totalTextContent = "";
    this.currentSegmentText = "";
    this.lastEmittedText = "";
    this.thinkingContent = "";
    this.toolCalls = /* @__PURE__ */ new Map();
    this.toolCallOrder = [];
    this.finishReason = null;
    this.hasError = false;
    this.isDone = false;
    this.recording = null;
    this.recordingStartTime = 0;
    this.chunkStrategy = options.chunkStrategy || new ImmediateStrategy();
    this.events = options.events || {};
    this.jsonParser = options.jsonParser || defaultJSONParser;
    this.recordingEnabled = options.recording ?? false;
    if (options.initialMessages) {
      this.messages = [...options.initialMessages];
    }
  }
  // ============================================
  // Message Management Methods
  // ============================================
  /**
   * Set the messages array (e.g., from persisted state)
   */
  setMessages(messages) {
    this.messages = [...messages];
    this.emitMessagesChange();
  }
  /**
   * Add a user message to the conversation.
   * Supports both simple string content and multimodal content arrays.
   *
   * @param content - The message content (string or array of content parts)
   * @param id - Optional custom message ID (generated if not provided)
   * @returns The created UIMessage
   *
   * @example
   * ```ts
   * // Simple text message
   * processor.addUserMessage('Hello!')
   *
   * // Multimodal message with image
   * processor.addUserMessage([
   *   { type: 'text', content: 'What is in this image?' },
   *   { type: 'image', source: { type: 'url', value: 'https://example.com/photo.jpg' } }
   * ])
   *
   * // With custom ID
   * processor.addUserMessage('Hello!', 'custom-id-123')
   * ```
   */
  addUserMessage(content, id) {
    const parts = typeof content === "string" ? [{ type: "text", content }] : content.map((part) => {
      return part;
    });
    const userMessage = {
      id: id ?? generateMessageId(),
      role: "user",
      parts,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.messages = [...this.messages, userMessage];
    this.emitMessagesChange();
    return userMessage;
  }
  /**
   * Prepare for a new assistant message stream.
   * Does NOT create the message immediately -- the message is created lazily
   * when the first content-bearing chunk arrives via ensureAssistantMessage().
   * This prevents empty assistant messages from flickering in the UI when
   * auto-continuation produces no content.
   */
  prepareAssistantMessage() {
    this.resetStreamState();
    this.currentAssistantMessageId = null;
  }
  /**
   * @deprecated Use prepareAssistantMessage() instead. This eagerly creates
   * an assistant message which can cause empty message flicker.
   */
  startAssistantMessage() {
    this.prepareAssistantMessage();
    return this.ensureAssistantMessage();
  }
  /**
   * Get the current assistant message ID (if one has been created).
   * Returns null if prepareAssistantMessage() was called but no content
   * has arrived yet.
   */
  getCurrentAssistantMessageId() {
    return this.currentAssistantMessageId;
  }
  /**
   * Lazily create the assistant message if it hasn't been created yet.
   * Called by content handlers on the first content-bearing chunk.
   * Returns the message ID.
   *
   * Content-bearing chunks that trigger this:
   * TEXT_MESSAGE_CONTENT, TOOL_CALL_START, STEP_FINISHED, RUN_ERROR.
   *
   * @see docs/chat-architecture.md#streamprocessor-internal-state — Lazy creation pattern
   */
  ensureAssistantMessage() {
    if (this.currentAssistantMessageId) {
      return this.currentAssistantMessageId;
    }
    const assistantMessage = {
      id: generateMessageId(),
      role: "assistant",
      parts: [],
      createdAt: /* @__PURE__ */ new Date()
    };
    this.currentAssistantMessageId = assistantMessage.id;
    this.messages = [...this.messages, assistantMessage];
    this.events.onStreamStart?.();
    this.emitMessagesChange();
    return assistantMessage.id;
  }
  /**
   * Add a tool result (called by client after handling onToolCall)
   */
  addToolResult(toolCallId, output, error) {
    const messageWithToolCall = this.messages.find(
      (msg) => msg.parts.some(
        (p) => p.type === "tool-call" && p.id === toolCallId
      )
    );
    if (!messageWithToolCall) {
      console.warn(
        `[StreamProcessor] Could not find message with tool call ${toolCallId}`
      );
      return;
    }
    let updatedMessages = updateToolCallWithOutput(
      this.messages,
      toolCallId,
      output,
      error ? "input-complete" : void 0,
      error
    );
    const content = typeof output === "string" ? output : JSON.stringify(output);
    const toolResultState = error ? "error" : "complete";
    updatedMessages = updateToolResultPart(
      updatedMessages,
      messageWithToolCall.id,
      toolCallId,
      content,
      toolResultState,
      error
    );
    this.messages = updatedMessages;
    this.emitMessagesChange();
  }
  /**
   * Add an approval response (called by client after handling onApprovalRequest)
   */
  addToolApprovalResponse(approvalId, approved) {
    this.messages = updateToolCallApprovalResponse(
      this.messages,
      approvalId,
      approved
    );
    this.emitMessagesChange();
  }
  /**
   * Get the conversation as ModelMessages (for sending to LLM)
   */
  toModelMessages() {
    const modelMessages = [];
    for (const msg of this.messages) {
      modelMessages.push(...uiMessageToModelMessages(msg));
    }
    return modelMessages;
  }
  /**
   * Get current messages
   */
  getMessages() {
    return this.messages;
  }
  /**
   * Check if all tool calls in the last assistant message are complete
   * Useful for auto-continue logic
   */
  areAllToolsComplete() {
    const lastAssistant = this.messages.findLast(
      (m) => m.role === "assistant"
    );
    if (!lastAssistant) return true;
    const toolParts = lastAssistant.parts.filter(
      (p) => p.type === "tool-call"
    );
    if (toolParts.length === 0) return true;
    const toolResultIds = new Set(
      lastAssistant.parts.filter((p) => p.type === "tool-result").map((p) => p.toolCallId)
    );
    return toolParts.every(
      (part) => part.state === "approval-responded" || part.output !== void 0 && !part.approval || toolResultIds.has(part.id)
    );
  }
  /**
   * Remove messages after a certain index (for reload/retry)
   */
  removeMessagesAfter(index) {
    this.messages = this.messages.slice(0, index + 1);
    this.emitMessagesChange();
  }
  /**
   * Clear all messages
   */
  clearMessages() {
    this.messages = [];
    this.currentAssistantMessageId = null;
    this.emitMessagesChange();
  }
  // ============================================
  // Stream Processing Methods
  // ============================================
  /**
   * Process a stream and emit events through handlers
   */
  async process(stream) {
    this.resetStreamState();
    if (this.recordingEnabled) {
      this.startRecording();
    }
    for await (const chunk of stream) {
      this.processChunk(chunk);
    }
    this.finalizeStream();
    if (this.recording) {
      this.recording.result = this.getResult();
    }
    return this.getResult();
  }
  /**
   * Process a single chunk from the stream.
   *
   * Central dispatch for all AG-UI events. Each event type maps to a specific
   * handler. Events not listed in the switch are intentionally ignored
   * (RUN_STARTED, TEXT_MESSAGE_END, STEP_STARTED, STATE_SNAPSHOT, STATE_DELTA).
   *
   * @see docs/chat-architecture.md#adapter-contract — Expected event types and ordering
   */
  processChunk(chunk) {
    if (this.recording) {
      this.recording.chunks.push({
        chunk,
        timestamp: Date.now(),
        index: this.recording.chunks.length
      });
    }
    switch (chunk.type) {
      // AG-UI Events
      case "TEXT_MESSAGE_START":
        this.handleTextMessageStartEvent();
        break;
      case "TEXT_MESSAGE_CONTENT":
        this.handleTextMessageContentEvent(chunk);
        break;
      case "TOOL_CALL_START":
        this.handleToolCallStartEvent(chunk);
        break;
      case "TOOL_CALL_ARGS":
        this.handleToolCallArgsEvent(chunk);
        break;
      case "TOOL_CALL_END":
        this.handleToolCallEndEvent(chunk);
        break;
      case "RUN_FINISHED":
        this.handleRunFinishedEvent(chunk);
        break;
      case "RUN_ERROR":
        this.handleRunErrorEvent(chunk);
        break;
      case "STEP_FINISHED":
        this.handleStepFinishedEvent(chunk);
        break;
      case "CUSTOM":
        this.handleCustomEvent(chunk);
        break;
    }
  }
  /**
   * Handle TEXT_MESSAGE_START event — marks the beginning of a new text segment.
   * Resets segment accumulation so text after tool calls starts fresh.
   *
   * This is the key mechanism for multi-segment text (text before and after tool
   * calls becoming separate TextParts). Without this reset, all text would merge
   * into a single TextPart and tool-call interleaving would be lost.
   *
   * @see docs/chat-architecture.md#single-shot-text-response — Step-by-step text processing
   * @see docs/chat-architecture.md#text-then-tool-interleaving-single-shot — Multi-segment text
   */
  handleTextMessageStartEvent() {
    if (this.currentSegmentText !== this.lastEmittedText) {
      this.emitTextUpdate();
    }
    this.currentSegmentText = "";
    this.lastEmittedText = "";
  }
  /**
   * Handle TEXT_MESSAGE_CONTENT event.
   *
   * Accumulates delta into both currentSegmentText (for UI emission) and
   * totalTextContent (for ProcessorResult). Lazily creates the assistant
   * UIMessage on first content. Uses updateTextPart() which replaces the
   * last TextPart or creates a new one depending on part ordering.
   *
   * @see docs/chat-architecture.md#single-shot-text-response — Text accumulation step-by-step
   * @see docs/chat-architecture.md#uimessage-part-ordering-invariants — Replace vs. push logic
   */
  handleTextMessageContentEvent(chunk) {
    this.ensureAssistantMessage();
    this.currentSegmentText += chunk.delta;
    this.totalTextContent += chunk.delta;
    const shouldEmit = this.chunkStrategy.shouldEmit(
      chunk.delta,
      this.currentSegmentText
    );
    if (shouldEmit && this.currentSegmentText !== this.lastEmittedText) {
      this.emitTextUpdate();
    }
  }
  /**
   * Handle TOOL_CALL_START event.
   *
   * Creates a new InternalToolCallState entry in the toolCalls Map and appends
   * a ToolCallPart to the UIMessage. Duplicate toolCallId is a no-op.
   *
   * CRITICAL: This MUST be received before any TOOL_CALL_ARGS for the same
   * toolCallId. Args for unknown IDs are silently dropped.
   *
   * @see docs/chat-architecture.md#single-shot-tool-call-response — Tool call state transitions
   * @see docs/chat-architecture.md#parallel-tool-calls-single-shot — Parallel tracking by ID
   * @see docs/chat-architecture.md#adapter-contract — Ordering requirements
   */
  handleToolCallStartEvent(chunk) {
    this.ensureAssistantMessage();
    const toolCallId = chunk.toolCallId;
    const existingToolCall = this.toolCalls.get(toolCallId);
    if (!existingToolCall) {
      const initialState = "awaiting-input";
      const newToolCall = {
        id: chunk.toolCallId,
        name: chunk.toolName,
        arguments: "",
        state: initialState,
        parsedArguments: void 0,
        index: chunk.index ?? this.toolCalls.size
      };
      this.toolCalls.set(toolCallId, newToolCall);
      this.toolCallOrder.push(toolCallId);
      if (this.currentAssistantMessageId) {
        this.messages = updateToolCallPart(
          this.messages,
          this.currentAssistantMessageId,
          {
            id: chunk.toolCallId,
            name: chunk.toolName,
            arguments: "",
            state: initialState
          }
        );
        this.emitMessagesChange();
        this.events.onToolCallStateChange?.(
          this.currentAssistantMessageId,
          chunk.toolCallId,
          initialState,
          ""
        );
      }
    }
  }
  /**
   * Handle TOOL_CALL_ARGS event.
   *
   * Appends the delta to the tool call's accumulated arguments string.
   * Transitions state from awaiting-input → input-streaming on first non-empty delta.
   * Attempts partial JSON parse on each update for UI preview.
   *
   * If toolCallId is not found in the Map (no preceding TOOL_CALL_START),
   * this event is silently dropped.
   *
   * @see docs/chat-architecture.md#single-shot-tool-call-response — Step-by-step tool call processing
   */
  handleToolCallArgsEvent(chunk) {
    const toolCallId = chunk.toolCallId;
    const existingToolCall = this.toolCalls.get(toolCallId);
    if (existingToolCall) {
      const wasAwaitingInput = existingToolCall.state === "awaiting-input";
      existingToolCall.arguments += chunk.delta || "";
      if (wasAwaitingInput && chunk.delta) {
        existingToolCall.state = "input-streaming";
      }
      existingToolCall.parsedArguments = this.jsonParser.parse(
        existingToolCall.arguments
      );
      if (this.currentAssistantMessageId) {
        this.messages = updateToolCallPart(
          this.messages,
          this.currentAssistantMessageId,
          {
            id: existingToolCall.id,
            name: existingToolCall.name,
            arguments: existingToolCall.arguments,
            state: existingToolCall.state
          }
        );
        this.emitMessagesChange();
        this.events.onToolCallStateChange?.(
          this.currentAssistantMessageId,
          existingToolCall.id,
          existingToolCall.state,
          existingToolCall.arguments
        );
      }
    }
  }
  /**
   * Handle TOOL_CALL_END event — authoritative signal that a tool call's input is finalized.
   *
   * This event has a DUAL ROLE:
   * - Without `result`: Signals arguments are done (from adapter). Transitions to input-complete.
   * - With `result`: Signals tool was executed and result is available (from TextEngine).
   *   Creates both output on the tool-call part AND a tool-result part.
   *
   * If `input` is provided, it overrides the accumulated string parse as the
   * canonical parsed arguments.
   *
   * @see docs/chat-architecture.md#tool-results-and-the-tool_call_end-dual-role — Full explanation
   * @see docs/chat-architecture.md#single-shot-tool-call-response — End-to-end flow
   */
  handleToolCallEndEvent(chunk) {
    const existingToolCall = this.toolCalls.get(chunk.toolCallId);
    if (existingToolCall && existingToolCall.state !== "input-complete") {
      const index = this.toolCallOrder.indexOf(chunk.toolCallId);
      this.completeToolCall(index, existingToolCall);
      if (chunk.input !== void 0) {
        existingToolCall.parsedArguments = chunk.input;
      }
    }
    if (this.currentAssistantMessageId && chunk.result) {
      const state = "complete";
      let output;
      try {
        output = JSON.parse(chunk.result);
      } catch {
        output = chunk.result;
      }
      this.messages = updateToolCallWithOutput(
        this.messages,
        chunk.toolCallId,
        output
      );
      this.messages = updateToolResultPart(
        this.messages,
        this.currentAssistantMessageId,
        chunk.toolCallId,
        chunk.result,
        state
      );
      this.emitMessagesChange();
    }
  }
  /**
   * Handle RUN_FINISHED event.
   *
   * Records the finishReason and calls completeAllToolCalls() as a safety net
   * to force-complete any tool calls that didn't receive an explicit TOOL_CALL_END.
   * This handles cases like aborted streams or adapter bugs.
   *
   * @see docs/chat-architecture.md#single-shot-tool-call-response — finishReason semantics
   * @see docs/chat-architecture.md#adapter-contract — Why RUN_FINISHED is mandatory
   */
  handleRunFinishedEvent(chunk) {
    this.finishReason = chunk.finishReason;
    this.isDone = true;
    this.completeAllToolCalls();
  }
  /**
   * Handle RUN_ERROR event
   */
  handleRunErrorEvent(chunk) {
    this.hasError = true;
    this.ensureAssistantMessage();
    this.events.onError?.(new Error(chunk.error.message || "An error occurred"));
  }
  /**
   * Handle STEP_FINISHED event (for thinking/reasoning content).
   *
   * Accumulates delta into thinkingContent and updates a single ThinkingPart
   * in the UIMessage (replaced in-place, not appended).
   *
   * @see docs/chat-architecture.md#thinkingreasoning-content — Thinking flow
   */
  handleStepFinishedEvent(chunk) {
    this.ensureAssistantMessage();
    this.thinkingContent += chunk.delta;
    if (this.currentAssistantMessageId) {
      this.messages = updateThinkingPart(
        this.messages,
        this.currentAssistantMessageId,
        this.thinkingContent
      );
      this.emitMessagesChange();
      this.events.onThinkingUpdate?.(
        this.currentAssistantMessageId,
        this.thinkingContent
      );
    }
  }
  /**
   * Handle CUSTOM event.
   *
   * Handles special custom events emitted by the TextEngine (not adapters):
   * - 'tool-input-available': Client tool needs execution. Fires onToolCall.
   * - 'approval-requested': Tool needs user approval. Updates tool-call part
   *   state and fires onApprovalRequest.
   *
   * @see docs/chat-architecture.md#client-tools-and-approval-flows — Full flow details
   */
  handleCustomEvent(chunk) {
    if (chunk.name === "tool-input-available" && chunk.data) {
      const { toolCallId, toolName, input } = chunk.data;
      this.events.onToolCall?.({
        toolCallId,
        toolName,
        input
      });
    }
    if (chunk.name === "approval-requested" && chunk.data) {
      const { toolCallId, toolName, input, approval } = chunk.data;
      if (this.currentAssistantMessageId) {
        this.messages = updateToolCallApproval(
          this.messages,
          this.currentAssistantMessageId,
          toolCallId,
          approval.id
        );
        this.emitMessagesChange();
      }
      this.events.onApprovalRequest?.({
        toolCallId,
        toolName,
        input,
        approvalId: approval.id
      });
    }
  }
  /**
   * Complete all tool calls — safety net for stream termination.
   *
   * Called by RUN_FINISHED and finalizeStream(). Force-transitions any tool call
   * not yet in input-complete state. Handles cases where TOOL_CALL_END was
   * missed (adapter bug, network error, aborted stream).
   *
   * @see docs/chat-architecture.md#single-shot-tool-call-response — Safety net behavior
   */
  completeAllToolCalls() {
    this.toolCalls.forEach((toolCall, id) => {
      if (toolCall.state !== "input-complete") {
        const index = this.toolCallOrder.indexOf(id);
        this.completeToolCall(index, toolCall);
      }
    });
  }
  /**
   * Mark a tool call as complete and emit event
   */
  completeToolCall(_index, toolCall) {
    toolCall.state = "input-complete";
    toolCall.parsedArguments = this.jsonParser.parse(toolCall.arguments);
    if (this.currentAssistantMessageId) {
      this.messages = updateToolCallPart(
        this.messages,
        this.currentAssistantMessageId,
        {
          id: toolCall.id,
          name: toolCall.name,
          arguments: toolCall.arguments,
          state: "input-complete"
        }
      );
      this.emitMessagesChange();
      this.events.onToolCallStateChange?.(
        this.currentAssistantMessageId,
        toolCall.id,
        "input-complete",
        toolCall.arguments
      );
    }
  }
  /**
   * Emit pending text update.
   *
   * Calls updateTextPart() which has critical append-vs-replace logic:
   * - If last UIMessage part is TextPart → replaces its content (same segment).
   * - If last part is anything else → pushes new TextPart (new segment after tools).
   *
   * @see docs/chat-architecture.md#uimessage-part-ordering-invariants — Replace vs. push logic
   */
  emitTextUpdate() {
    this.lastEmittedText = this.currentSegmentText;
    if (this.currentAssistantMessageId) {
      this.messages = updateTextPart(
        this.messages,
        this.currentAssistantMessageId,
        this.currentSegmentText
      );
      this.emitMessagesChange();
      this.events.onTextUpdate?.(
        this.currentAssistantMessageId,
        this.currentSegmentText
      );
    }
  }
  /**
   * Emit messages change event
   */
  emitMessagesChange() {
    this.events.onMessagesChange?.([...this.messages]);
  }
  /**
   * Finalize the stream — complete all pending operations.
   *
   * Called when the async iterable ends (stream closed). Acts as the final
   * safety net: completes any remaining tool calls, flushes un-emitted text,
   * and fires onStreamEnd.
   *
   * @see docs/chat-architecture.md#single-shot-text-response — Finalization step
   */
  finalizeStream() {
    this.completeAllToolCalls();
    if (this.currentSegmentText !== this.lastEmittedText) {
      this.emitTextUpdate();
    }
    if (this.currentAssistantMessageId && !this.hasError) {
      const assistantMessage = this.messages.find(
        (m) => m.id === this.currentAssistantMessageId
      );
      if (assistantMessage && this.isWhitespaceOnlyMessage(assistantMessage)) {
        this.messages = this.messages.filter(
          (m) => m.id !== this.currentAssistantMessageId
        );
        this.emitMessagesChange();
        this.currentAssistantMessageId = null;
        return;
      }
    }
    if (this.currentAssistantMessageId) {
      const assistantMessage = this.messages.find(
        (m) => m.id === this.currentAssistantMessageId
      );
      if (assistantMessage) {
        this.events.onStreamEnd?.(assistantMessage);
      }
    }
  }
  /**
   * Get completed tool calls in API format
   */
  getCompletedToolCalls() {
    return Array.from(this.toolCalls.values()).filter((tc) => tc.state === "input-complete").map((tc) => ({
      id: tc.id,
      type: "function",
      function: {
        name: tc.name,
        arguments: tc.arguments
      }
    }));
  }
  /**
   * Get current result
   */
  getResult() {
    const toolCalls = this.getCompletedToolCalls();
    return {
      content: this.totalTextContent,
      thinking: this.thinkingContent || void 0,
      toolCalls: toolCalls.length > 0 ? toolCalls : void 0,
      finishReason: this.finishReason
    };
  }
  /**
   * Get current processor state
   */
  getState() {
    return {
      content: this.totalTextContent,
      thinking: this.thinkingContent,
      toolCalls: new Map(this.toolCalls),
      toolCallOrder: [...this.toolCallOrder],
      finishReason: this.finishReason,
      done: this.isDone
    };
  }
  /**
   * Start recording chunks
   */
  startRecording() {
    this.recordingEnabled = true;
    this.recordingStartTime = Date.now();
    this.recording = {
      version: "1.0",
      timestamp: this.recordingStartTime,
      chunks: []
    };
  }
  /**
   * Get the current recording
   */
  getRecording() {
    return this.recording;
  }
  /**
   * Reset stream state (but keep messages)
   */
  resetStreamState() {
    this.totalTextContent = "";
    this.currentSegmentText = "";
    this.lastEmittedText = "";
    this.thinkingContent = "";
    this.toolCalls.clear();
    this.toolCallOrder = [];
    this.finishReason = null;
    this.hasError = false;
    this.isDone = false;
    this.chunkStrategy.reset?.();
  }
  /**
   * Full reset (including messages)
   */
  reset() {
    this.resetStreamState();
    this.messages = [];
    this.currentAssistantMessageId = null;
  }
  /**
   * Check if a message contains only whitespace text and no other meaningful parts
   * (no tool calls, tool results, thinking, etc.)
   */
  isWhitespaceOnlyMessage(message) {
    if (message.parts.length === 0) return false;
    return message.parts.every(
      (part) => part.type === "text" && part.content.trim() === ""
    );
  }
  /**
   * Replay a recording through the processor
   */
  static async replay(recording, options) {
    const processor = new StreamProcessor(options);
    return processor.process(createReplayStream(recording));
  }
}
function createReplayStream(recording) {
  return {
    // eslint-disable-next-line @typescript-eslint/require-await
    async *[Symbol.asyncIterator]() {
      for (const { chunk } of recording.chunks) {
        yield chunk;
      }
    }
  };
}
export {
  StreamProcessor,
  createReplayStream
};
//# sourceMappingURL=processor.js.map
