import { BaseTextAdapter } from "@tanstack/ai/adapters";
import { convertToolsToProviderFormat } from "../tools/tool-converter.js";
import { validateTextProviderOptions } from "../text/text-provider-options.js";
import { createAnthropicClient, generateId, getAnthropicApiKeyFromEnv } from "../utils/client.js";
class AnthropicTextAdapter extends BaseTextAdapter {
  constructor(config, model) {
    super({}, model);
    this.kind = "text";
    this.name = "anthropic";
    this.client = createAnthropicClient(config);
  }
  async *chatStream(options) {
    try {
      const requestParams = this.mapCommonOptionsToAnthropic(options);
      const stream = await this.client.beta.messages.create(
        { ...requestParams, stream: true },
        {
          signal: options.request?.signal,
          headers: options.request?.headers
        }
      );
      yield* this.processAnthropicStream(
        stream,
        options.model,
        () => generateId(this.name)
      );
    } catch (error) {
      const err = error;
      yield {
        type: "RUN_ERROR",
        model: options.model,
        timestamp: Date.now(),
        error: {
          message: err.message || "Unknown error occurred",
          code: err.code || String(err.status)
        }
      };
    }
  }
  /**
   * Generate structured output using Anthropic's tool-based approach.
   * Anthropic doesn't have native structured output, so we use a tool with the schema
   * and force the model to call it.
   * The outputSchema is already JSON Schema (converted in the ai layer).
   */
  async structuredOutput(options) {
    const { chatOptions, outputSchema } = options;
    const requestParams = this.mapCommonOptionsToAnthropic(chatOptions);
    const structuredOutputTool = {
      name: "structured_output",
      description: "Use this tool to provide your response in the required structured format.",
      input_schema: {
        type: "object",
        properties: outputSchema.properties ?? {},
        required: outputSchema.required ?? []
      }
    };
    try {
      const response = await this.client.messages.create(
        {
          ...requestParams,
          stream: false,
          tools: [structuredOutputTool],
          tool_choice: { type: "tool", name: "structured_output" }
        },
        {
          signal: chatOptions.request?.signal,
          headers: chatOptions.request?.headers
        }
      );
      let parsed = null;
      let rawText = "";
      for (const block of response.content) {
        if (block.type === "tool_use" && block.name === "structured_output") {
          parsed = block.input;
          rawText = JSON.stringify(block.input);
          break;
        }
      }
      if (parsed === null) {
        rawText = response.content.map((b) => {
          if (b.type === "text") {
            return b.text;
          }
          return "";
        }).join("");
        try {
          parsed = JSON.parse(rawText);
        } catch {
          throw new Error(
            `Failed to extract structured output from response. Content: ${rawText.slice(0, 200)}${rawText.length > 200 ? "..." : ""}`
          );
        }
      }
      return {
        data: parsed,
        rawText
      };
    } catch (error) {
      const err = error;
      throw new Error(
        `Structured output generation failed: ${err.message || "Unknown error occurred"}`
      );
    }
  }
  mapCommonOptionsToAnthropic(options) {
    const modelOptions = options.modelOptions;
    const formattedMessages = this.formatMessages(options.messages);
    const tools = options.tools ? convertToolsToProviderFormat(options.tools) : void 0;
    const validProviderOptions = {};
    if (modelOptions) {
      const validKeys = [
        "container",
        "context_management",
        "effort",
        "mcp_servers",
        "service_tier",
        "stop_sequences",
        "system",
        "thinking",
        "tool_choice",
        "top_k"
      ];
      for (const key of validKeys) {
        if (key in modelOptions) {
          const value = modelOptions[key];
          if (key === "tool_choice" && typeof value === "string") {
            validProviderOptions[key] = {
              type: value
            };
          } else {
            validProviderOptions[key] = value;
          }
        }
      }
    }
    const thinkingBudget = validProviderOptions.thinking?.type === "enabled" ? validProviderOptions.thinking.budget_tokens : void 0;
    const defaultMaxTokens = options.maxTokens || 1024;
    const maxTokens = thinkingBudget && thinkingBudget >= defaultMaxTokens ? thinkingBudget + 1 : defaultMaxTokens;
    const requestParams = {
      model: options.model,
      max_tokens: maxTokens,
      temperature: options.temperature,
      top_p: options.topP,
      messages: formattedMessages,
      system: options.systemPrompts?.join("\n"),
      tools,
      ...validProviderOptions
    };
    validateTextProviderOptions(requestParams);
    return requestParams;
  }
  convertContentPartToAnthropic(part) {
    switch (part.type) {
      case "text": {
        const metadata = part.metadata;
        return {
          type: "text",
          text: part.content,
          ...metadata
        };
      }
      case "image": {
        const metadata = part.metadata;
        const imageSource = part.source.type === "data" ? {
          type: "base64",
          data: part.source.value,
          media_type: part.source.mimeType
        } : {
          type: "url",
          url: part.source.value
        };
        return {
          type: "image",
          source: imageSource,
          ...metadata
        };
      }
      case "document": {
        const metadata = part.metadata;
        const docSource = part.source.type === "data" ? {
          type: "base64",
          data: part.source.value,
          media_type: part.source.mimeType
        } : {
          type: "url",
          url: part.source.value
        };
        return {
          type: "document",
          source: docSource,
          ...metadata
        };
      }
      case "audio":
      case "video":
        throw new Error(
          `Anthropic does not support ${part.type} content directly`
        );
      default: {
        const _exhaustiveCheck = part;
        throw new Error(
          `Unsupported content part type: ${_exhaustiveCheck.type}`
        );
      }
    }
  }
  formatMessages(messages) {
    const formattedMessages = [];
    for (const message of messages) {
      const role = message.role;
      if (role === "tool" && message.toolCallId) {
        formattedMessages.push({
          role: "user",
          content: [
            {
              type: "tool_result",
              tool_use_id: message.toolCallId,
              content: typeof message.content === "string" ? message.content : ""
            }
          ]
        });
        continue;
      }
      if (role === "assistant" && message.toolCalls?.length) {
        const contentBlocks = [];
        if (message.content) {
          const content = typeof message.content === "string" ? message.content : "";
          const textBlock = {
            type: "text",
            text: content
          };
          contentBlocks.push(textBlock);
        }
        for (const toolCall of message.toolCalls) {
          let parsedInput = {};
          try {
            const parsed = toolCall.function.arguments ? JSON.parse(toolCall.function.arguments) : {};
            parsedInput = parsed && typeof parsed === "object" ? parsed : {};
          } catch {
            parsedInput = toolCall.function.arguments;
          }
          const toolUseBlock = {
            type: "tool_use",
            id: toolCall.id,
            name: toolCall.function.name,
            input: parsedInput
          };
          contentBlocks.push(toolUseBlock);
        }
        formattedMessages.push({
          role: "assistant",
          content: contentBlocks
        });
        continue;
      }
      if (role === "user" && Array.isArray(message.content)) {
        const contentBlocks = message.content.map(
          (part) => this.convertContentPartToAnthropic(part)
        );
        formattedMessages.push({
          role: "user",
          content: contentBlocks
        });
        continue;
      }
      formattedMessages.push({
        role: role === "assistant" ? "assistant" : "user",
        content: typeof message.content === "string" ? message.content : message.content ? message.content.map(
          (c) => this.convertContentPartToAnthropic(c)
        ) : ""
      });
    }
    return this.mergeConsecutiveSameRoleMessages(formattedMessages);
  }
  /**
   * Merge consecutive messages of the same role into a single message.
   * Anthropic's API requires strictly alternating user/assistant roles.
   * Tool results are wrapped as role:'user' messages, which can collide
   * with actual user messages in multi-turn conversations.
   *
   * Also filters out empty assistant messages (e.g., from a previous failed request).
   */
  mergeConsecutiveSameRoleMessages(messages) {
    const merged = [];
    for (const msg of messages) {
      if (msg.role === "assistant") {
        const hasContent = Array.isArray(msg.content) ? msg.content.length > 0 : typeof msg.content === "string" && msg.content.length > 0;
        if (!hasContent) {
          continue;
        }
      }
      const prev = merged[merged.length - 1];
      if (prev && prev.role === msg.role) {
        const prevBlocks = Array.isArray(prev.content) ? prev.content : typeof prev.content === "string" && prev.content ? [{ type: "text", text: prev.content }] : [];
        const msgBlocks = Array.isArray(msg.content) ? msg.content : typeof msg.content === "string" && msg.content ? [{ type: "text", text: msg.content }] : [];
        prev.content = [...prevBlocks, ...msgBlocks];
      } else {
        merged.push({ ...msg });
      }
    }
    for (const msg of merged) {
      if (Array.isArray(msg.content)) {
        const seenToolResultIds = /* @__PURE__ */ new Set();
        msg.content = msg.content.filter((block) => {
          if (block.type === "tool_result" && block.tool_use_id) {
            if (seenToolResultIds.has(block.tool_use_id)) {
              return false;
            }
            seenToolResultIds.add(block.tool_use_id);
          }
          return true;
        });
      }
    }
    return merged;
  }
  async *processAnthropicStream(stream, model, genId) {
    let accumulatedContent = "";
    let accumulatedThinking = "";
    const timestamp = Date.now();
    const toolCallsMap = /* @__PURE__ */ new Map();
    let currentToolIndex = -1;
    const runId = genId();
    const messageId = genId();
    let stepId = null;
    let hasEmittedRunStarted = false;
    let hasEmittedTextMessageStart = false;
    let hasEmittedRunFinished = false;
    let currentBlockType = null;
    try {
      for await (const event of stream) {
        if (!hasEmittedRunStarted) {
          hasEmittedRunStarted = true;
          yield {
            type: "RUN_STARTED",
            runId,
            model,
            timestamp
          };
        }
        if (event.type === "content_block_start") {
          currentBlockType = event.content_block.type;
          if (event.content_block.type === "tool_use") {
            currentToolIndex++;
            toolCallsMap.set(currentToolIndex, {
              id: event.content_block.id,
              name: event.content_block.name,
              input: "",
              started: false
            });
          } else if (event.content_block.type === "thinking") {
            accumulatedThinking = "";
            stepId = genId();
            yield {
              type: "STEP_STARTED",
              stepId,
              model,
              timestamp,
              stepType: "thinking"
            };
          }
        } else if (event.type === "content_block_delta") {
          if (event.delta.type === "text_delta") {
            if (!hasEmittedTextMessageStart) {
              hasEmittedTextMessageStart = true;
              yield {
                type: "TEXT_MESSAGE_START",
                messageId,
                model,
                timestamp,
                role: "assistant"
              };
            }
            const delta = event.delta.text;
            accumulatedContent += delta;
            yield {
              type: "TEXT_MESSAGE_CONTENT",
              messageId,
              model,
              timestamp,
              delta,
              content: accumulatedContent
            };
          } else if (event.delta.type === "thinking_delta") {
            const delta = event.delta.thinking;
            accumulatedThinking += delta;
            yield {
              type: "STEP_FINISHED",
              stepId: stepId || genId(),
              model,
              timestamp,
              delta,
              content: accumulatedThinking
            };
          } else if (event.delta.type === "input_json_delta") {
            const existing = toolCallsMap.get(currentToolIndex);
            if (existing) {
              if (!existing.started) {
                existing.started = true;
                yield {
                  type: "TOOL_CALL_START",
                  toolCallId: existing.id,
                  toolName: existing.name,
                  model,
                  timestamp,
                  index: currentToolIndex
                };
              }
              existing.input += event.delta.partial_json;
              yield {
                type: "TOOL_CALL_ARGS",
                toolCallId: existing.id,
                model,
                timestamp,
                delta: event.delta.partial_json,
                args: existing.input
              };
            }
          }
        } else if (event.type === "content_block_stop") {
          if (currentBlockType === "tool_use") {
            const existing = toolCallsMap.get(currentToolIndex);
            if (existing) {
              if (!existing.started) {
                existing.started = true;
                yield {
                  type: "TOOL_CALL_START",
                  toolCallId: existing.id,
                  toolName: existing.name,
                  model,
                  timestamp,
                  index: currentToolIndex
                };
              }
              let parsedInput = {};
              try {
                const parsed = existing.input ? JSON.parse(existing.input) : {};
                parsedInput = parsed && typeof parsed === "object" ? parsed : {};
              } catch {
                parsedInput = {};
              }
              yield {
                type: "TOOL_CALL_END",
                toolCallId: existing.id,
                toolName: existing.name,
                model,
                timestamp,
                input: parsedInput
              };
              hasEmittedTextMessageStart = false;
            }
          } else {
            if (hasEmittedTextMessageStart && accumulatedContent) {
              yield {
                type: "TEXT_MESSAGE_END",
                messageId,
                model,
                timestamp
              };
            }
          }
          currentBlockType = null;
        } else if (event.type === "message_stop") {
          if (!hasEmittedRunFinished) {
            yield {
              type: "RUN_FINISHED",
              runId,
              model,
              timestamp,
              finishReason: "stop"
            };
          }
        } else if (event.type === "message_delta") {
          if (event.delta.stop_reason) {
            hasEmittedRunFinished = true;
            switch (event.delta.stop_reason) {
              case "tool_use": {
                yield {
                  type: "RUN_FINISHED",
                  runId,
                  model,
                  timestamp,
                  finishReason: "tool_calls",
                  usage: {
                    promptTokens: event.usage.input_tokens || 0,
                    completionTokens: event.usage.output_tokens || 0,
                    totalTokens: (event.usage.input_tokens || 0) + (event.usage.output_tokens || 0)
                  }
                };
                break;
              }
              case "max_tokens": {
                yield {
                  type: "RUN_ERROR",
                  runId,
                  model,
                  timestamp,
                  error: {
                    message: "The response was cut off because the maximum token limit was reached.",
                    code: "max_tokens"
                  }
                };
                break;
              }
              default: {
                yield {
                  type: "RUN_FINISHED",
                  runId,
                  model,
                  timestamp,
                  finishReason: "stop",
                  usage: {
                    promptTokens: event.usage.input_tokens || 0,
                    completionTokens: event.usage.output_tokens || 0,
                    totalTokens: (event.usage.input_tokens || 0) + (event.usage.output_tokens || 0)
                  }
                };
              }
            }
          }
        }
      }
    } catch (error) {
      const err = error;
      yield {
        type: "RUN_ERROR",
        runId,
        model,
        timestamp,
        error: {
          message: err.message || "Unknown error occurred",
          code: err.code || String(err.status)
        }
      };
    }
  }
}
function createAnthropicChat(model, apiKey, config) {
  return new AnthropicTextAdapter({ apiKey, ...config }, model);
}
function anthropicText(model, config) {
  const apiKey = getAnthropicApiKeyFromEnv();
  return createAnthropicChat(model, apiKey, config);
}
export {
  AnthropicTextAdapter,
  anthropicText,
  createAnthropicChat
};
//# sourceMappingURL=text.js.map
