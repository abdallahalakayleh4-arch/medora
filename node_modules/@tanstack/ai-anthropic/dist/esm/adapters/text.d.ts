import { BaseTextAdapter, StructuredOutputOptions, StructuredOutputResult } from '@tanstack/ai/adapters';
import { ANTHROPIC_MODELS, AnthropicChatModelProviderOptionsByName, AnthropicModelInputModalitiesByName } from '../model-meta.js';
import { Modality, StreamChunk, TextOptions } from '@tanstack/ai';
import { ExternalTextProviderOptions } from '../text/text-provider-options.js';
import { AnthropicMessageMetadataByModality } from '../message-types.js';
import { AnthropicClientConfig } from '../utils.js';
/**
 * Configuration for Anthropic text adapter
 */
export interface AnthropicTextConfig extends AnthropicClientConfig {
}
/**
 * Anthropic-specific provider options for text/chat
 */
export type AnthropicTextProviderOptions = ExternalTextProviderOptions;
/**
 * Resolve provider options for a specific model.
 * If the model has explicit options in the map, use those; otherwise use base options.
 */
type ResolveProviderOptions<TModel extends string> = TModel extends keyof AnthropicChatModelProviderOptionsByName ? AnthropicChatModelProviderOptionsByName[TModel] : AnthropicTextProviderOptions;
/**
 * Resolve input modalities for a specific model.
 * If the model has explicit modalities in the map, use those; otherwise use default.
 */
type ResolveInputModalities<TModel extends string> = TModel extends keyof AnthropicModelInputModalitiesByName ? AnthropicModelInputModalitiesByName[TModel] : readonly ['text', 'image', 'document'];
/**
 * Anthropic Text (Chat) Adapter
 *
 * Tree-shakeable adapter for Anthropic chat/text completion functionality.
 * Import only what you need for smaller bundle sizes.
 */
export declare class AnthropicTextAdapter<TModel extends (typeof ANTHROPIC_MODELS)[number], TProviderOptions extends object = ResolveProviderOptions<TModel>, TInputModalities extends ReadonlyArray<Modality> = ResolveInputModalities<TModel>> extends BaseTextAdapter<TModel, TProviderOptions, TInputModalities, AnthropicMessageMetadataByModality> {
    readonly kind: "text";
    readonly name: "anthropic";
    private client;
    constructor(config: AnthropicTextConfig, model: TModel);
    chatStream(options: TextOptions<AnthropicTextProviderOptions>): AsyncIterable<StreamChunk>;
    /**
     * Generate structured output using Anthropic's tool-based approach.
     * Anthropic doesn't have native structured output, so we use a tool with the schema
     * and force the model to call it.
     * The outputSchema is already JSON Schema (converted in the ai layer).
     */
    structuredOutput(options: StructuredOutputOptions<AnthropicTextProviderOptions>): Promise<StructuredOutputResult<unknown>>;
    private mapCommonOptionsToAnthropic;
    private convertContentPartToAnthropic;
    private formatMessages;
    /**
     * Merge consecutive messages of the same role into a single message.
     * Anthropic's API requires strictly alternating user/assistant roles.
     * Tool results are wrapped as role:'user' messages, which can collide
     * with actual user messages in multi-turn conversations.
     *
     * Also filters out empty assistant messages (e.g., from a previous failed request).
     */
    private mergeConsecutiveSameRoleMessages;
    private processAnthropicStream;
}
/**
 * Creates an Anthropic chat adapter with explicit API key.
 * Type resolution happens here at the call site.
 */
export declare function createAnthropicChat<TModel extends (typeof ANTHROPIC_MODELS)[number]>(model: TModel, apiKey: string, config?: Omit<AnthropicTextConfig, 'apiKey'>): AnthropicTextAdapter<TModel, ResolveProviderOptions<TModel>, ResolveInputModalities<TModel>>;
/**
 * Creates an Anthropic text adapter with automatic API key detection.
 * Type resolution happens here at the call site.
 */
export declare function anthropicText<TModel extends (typeof ANTHROPIC_MODELS)[number]>(model: TModel, config?: Omit<AnthropicTextConfig, 'apiKey'>): AnthropicTextAdapter<TModel, ResolveProviderOptions<TModel>, ResolveInputModalities<TModel>>;
export {};
