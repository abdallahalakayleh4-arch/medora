{"version":3,"file":"text.js","sources":["../../../src/adapters/text.ts"],"sourcesContent":["import { FinishReason } from '@google/genai'\nimport { BaseTextAdapter } from '@tanstack/ai/adapters'\nimport { convertToolsToProviderFormat } from '../tools/tool-converter'\nimport {\n  createGeminiClient,\n  generateId,\n  getGeminiApiKeyFromEnv,\n} from '../utils'\nimport type {\n  GEMINI_MODELS,\n  GeminiChatModelProviderOptionsByName,\n  GeminiModelInputModalitiesByName,\n} from '../model-meta'\nimport type {\n  StructuredOutputOptions,\n  StructuredOutputResult,\n} from '@tanstack/ai/adapters'\nimport type {\n  Content,\n  GenerateContentParameters,\n  GenerateContentResponse,\n  GoogleGenAI,\n  Part,\n  ThinkingLevel,\n} from '@google/genai'\nimport type {\n  ContentPart,\n  Modality,\n  ModelMessage,\n  StreamChunk,\n  TextOptions,\n} from '@tanstack/ai'\nimport type { ExternalTextProviderOptions } from '../text/text-provider-options'\nimport type { GeminiMessageMetadataByModality } from '../message-types'\nimport type { GeminiClientConfig } from '../utils'\n\n/**\n * Configuration for Gemini text adapter\n */\nexport interface GeminiTextConfig extends GeminiClientConfig {}\n\n/**\n * Gemini-specific provider options for text/chat\n */\nexport type GeminiTextProviderOptions = ExternalTextProviderOptions\n\n// ===========================\n// Type Resolution Helpers\n// ===========================\n\n/**\n * Resolve provider options for a specific model.\n * If the model has explicit options in the map, use those; otherwise use base options.\n */\ntype ResolveProviderOptions<TModel extends string> =\n  TModel extends keyof GeminiChatModelProviderOptionsByName\n    ? GeminiChatModelProviderOptionsByName[TModel]\n    : GeminiTextProviderOptions\n\n/**\n * Resolve input modalities for a specific model.\n * If the model has explicit modalities in the map, use those; otherwise use all modalities.\n */\ntype ResolveInputModalities<TModel extends string> =\n  TModel extends keyof GeminiModelInputModalitiesByName\n    ? GeminiModelInputModalitiesByName[TModel]\n    : readonly ['text', 'image', 'audio', 'video', 'document']\n\n// ===========================\n// Adapter Implementation\n// ===========================\n\n/**\n * Gemini Text (Chat) Adapter\n *\n * Tree-shakeable adapter for Gemini chat/text completion functionality.\n * Import only what you need for smaller bundle sizes.\n */\nexport class GeminiTextAdapter<\n  TModel extends (typeof GEMINI_MODELS)[number],\n  TProviderOptions extends object = ResolveProviderOptions<TModel>,\n  TInputModalities extends ReadonlyArray<Modality> =\n    ResolveInputModalities<TModel>,\n> extends BaseTextAdapter<\n  TModel,\n  TProviderOptions,\n  TInputModalities,\n  GeminiMessageMetadataByModality\n> {\n  readonly kind = 'text' as const\n  readonly name = 'gemini' as const\n\n  private client: GoogleGenAI\n\n  constructor(config: GeminiTextConfig, model: TModel) {\n    super({}, model)\n    this.client = createGeminiClient(config)\n  }\n\n  async *chatStream(\n    options: TextOptions<GeminiTextProviderOptions>,\n  ): AsyncIterable<StreamChunk> {\n    const mappedOptions = this.mapCommonOptionsToGemini(options)\n\n    try {\n      const result =\n        await this.client.models.generateContentStream(mappedOptions)\n\n      yield* this.processStreamChunks(result, options.model)\n    } catch (error) {\n      const timestamp = Date.now()\n      yield {\n        type: 'RUN_ERROR',\n        model: options.model,\n        timestamp,\n        error: {\n          message:\n            error instanceof Error\n              ? error.message\n              : 'An unknown error occurred during the chat stream.',\n        },\n      }\n    }\n  }\n\n  /**\n   * Generate structured output using Gemini's native JSON response format.\n   * Uses responseMimeType: 'application/json' and responseSchema for structured output.\n   * The outputSchema is already JSON Schema (converted in the ai layer).\n   */\n  async structuredOutput(\n    options: StructuredOutputOptions<GeminiTextProviderOptions>,\n  ): Promise<StructuredOutputResult<unknown>> {\n    const { chatOptions, outputSchema } = options\n\n    const mappedOptions = this.mapCommonOptionsToGemini(chatOptions)\n\n    try {\n      // Add structured output configuration\n      const result = await this.client.models.generateContent({\n        ...mappedOptions,\n        config: {\n          ...mappedOptions.config,\n          responseMimeType: 'application/json',\n          responseSchema: outputSchema,\n        },\n      })\n\n      // Extract text content from the response\n      const rawText = this.extractTextFromResponse(result)\n\n      // Parse the JSON response\n      let parsed: unknown\n      try {\n        parsed = JSON.parse(rawText)\n      } catch {\n        throw new Error(\n          `Failed to parse structured output as JSON. Content: ${rawText.slice(0, 200)}${rawText.length > 200 ? '...' : ''}`,\n        )\n      }\n\n      return {\n        data: parsed,\n        rawText,\n      }\n    } catch (error) {\n      throw new Error(\n        error instanceof Error\n          ? error.message\n          : 'An unknown error occurred during structured output generation.',\n      )\n    }\n  }\n\n  /**\n   * Extract text content from a non-streaming response\n   */\n  private extractTextFromResponse(response: GenerateContentResponse): string {\n    let textContent = ''\n\n    if (response.candidates?.[0]?.content?.parts) {\n      for (const part of response.candidates[0].content.parts) {\n        if (part.text) {\n          textContent += part.text\n        }\n      }\n    }\n\n    return textContent\n  }\n\n  private async *processStreamChunks(\n    result: AsyncGenerator<GenerateContentResponse, unknown, unknown>,\n    model: string,\n  ): AsyncIterable<StreamChunk> {\n    const timestamp = Date.now()\n    let accumulatedContent = ''\n    let accumulatedThinking = ''\n    const toolCallMap = new Map<\n      string,\n      { name: string; args: string; index: number; started: boolean }\n    >()\n    let nextToolIndex = 0\n\n    // AG-UI lifecycle tracking\n    const runId = generateId(this.name)\n    const messageId = generateId(this.name)\n    let stepId: string | null = null\n    let hasEmittedRunStarted = false\n    let hasEmittedTextMessageStart = false\n    let hasEmittedStepStarted = false\n\n    for await (const chunk of result) {\n      // Emit RUN_STARTED on first chunk\n      if (!hasEmittedRunStarted) {\n        hasEmittedRunStarted = true\n        yield {\n          type: 'RUN_STARTED',\n          runId,\n          model,\n          timestamp,\n        }\n      }\n\n      if (chunk.candidates?.[0]?.content?.parts) {\n        const parts = chunk.candidates[0].content.parts\n\n        for (const part of parts) {\n          if (part.text) {\n            if (part.thought) {\n              // Emit STEP_STARTED on first thinking content\n              if (!hasEmittedStepStarted) {\n                hasEmittedStepStarted = true\n                stepId = generateId(this.name)\n                yield {\n                  type: 'STEP_STARTED',\n                  stepId,\n                  model,\n                  timestamp,\n                  stepType: 'thinking',\n                }\n              }\n\n              accumulatedThinking += part.text\n              yield {\n                type: 'STEP_FINISHED',\n                stepId: stepId || generateId(this.name),\n                model,\n                timestamp,\n                delta: part.text,\n                content: accumulatedThinking,\n              }\n            } else if (part.text.trim()) {\n              // Skip whitespace-only text parts (e.g. \"\\n\" during auto-continuation)\n              // Emit TEXT_MESSAGE_START on first text content\n              if (!hasEmittedTextMessageStart) {\n                hasEmittedTextMessageStart = true\n                yield {\n                  type: 'TEXT_MESSAGE_START',\n                  messageId,\n                  model,\n                  timestamp,\n                  role: 'assistant',\n                }\n              }\n\n              accumulatedContent += part.text\n              yield {\n                type: 'TEXT_MESSAGE_CONTENT',\n                messageId,\n                model,\n                timestamp,\n                delta: part.text,\n                content: accumulatedContent,\n              }\n            }\n          }\n\n          const functionCall = part.functionCall\n          if (functionCall) {\n            const toolCallId =\n              functionCall.id ||\n              `${functionCall.name}_${Date.now()}_${nextToolIndex}`\n            const functionArgs = functionCall.args || {}\n\n            let toolCallData = toolCallMap.get(toolCallId)\n            if (!toolCallData) {\n              toolCallData = {\n                name: functionCall.name || '',\n                args:\n                  typeof functionArgs === 'string'\n                    ? functionArgs\n                    : JSON.stringify(functionArgs),\n                index: nextToolIndex++,\n                started: false,\n              }\n              toolCallMap.set(toolCallId, toolCallData)\n            } else {\n              try {\n                const existingArgs = JSON.parse(toolCallData.args)\n                const newArgs =\n                  typeof functionArgs === 'string'\n                    ? JSON.parse(functionArgs)\n                    : functionArgs\n                const mergedArgs = { ...existingArgs, ...newArgs }\n                toolCallData.args = JSON.stringify(mergedArgs)\n              } catch {\n                toolCallData.args =\n                  typeof functionArgs === 'string'\n                    ? functionArgs\n                    : JSON.stringify(functionArgs)\n              }\n            }\n\n            // Emit TOOL_CALL_START if not already started\n            if (!toolCallData.started) {\n              toolCallData.started = true\n              yield {\n                type: 'TOOL_CALL_START',\n                toolCallId,\n                toolName: toolCallData.name,\n                model,\n                timestamp,\n                index: toolCallData.index,\n              }\n            }\n\n            // Emit TOOL_CALL_ARGS\n            yield {\n              type: 'TOOL_CALL_ARGS',\n              toolCallId,\n              model,\n              timestamp,\n              delta: toolCallData.args,\n              args: toolCallData.args,\n            }\n          }\n        }\n      } else if (chunk.data && chunk.data.trim()) {\n        // Skip whitespace-only data (e.g. \"\\n\" during auto-continuation)\n        // Emit TEXT_MESSAGE_START on first text content\n        if (!hasEmittedTextMessageStart) {\n          hasEmittedTextMessageStart = true\n          yield {\n            type: 'TEXT_MESSAGE_START',\n            messageId,\n            model,\n            timestamp,\n            role: 'assistant',\n          }\n        }\n\n        accumulatedContent += chunk.data\n        yield {\n          type: 'TEXT_MESSAGE_CONTENT',\n          messageId,\n          model,\n          timestamp,\n          delta: chunk.data,\n          content: accumulatedContent,\n        }\n      }\n\n      if (chunk.candidates?.[0]?.finishReason) {\n        const finishReason = chunk.candidates[0].finishReason\n\n        if (finishReason === FinishReason.UNEXPECTED_TOOL_CALL) {\n          if (chunk.candidates[0].content?.parts) {\n            for (const part of chunk.candidates[0].content.parts) {\n              const functionCall = part.functionCall\n              if (functionCall) {\n                const toolCallId =\n                  functionCall.id ||\n                  `${functionCall.name}_${Date.now()}_${nextToolIndex}`\n                const functionArgs = functionCall.args || {}\n\n                const argsString =\n                  typeof functionArgs === 'string'\n                    ? functionArgs\n                    : JSON.stringify(functionArgs)\n\n                toolCallMap.set(toolCallId, {\n                  name: functionCall.name || '',\n                  args: argsString,\n                  index: nextToolIndex++,\n                  started: true,\n                })\n\n                // Emit TOOL_CALL_START\n                yield {\n                  type: 'TOOL_CALL_START',\n                  toolCallId,\n                  toolName: functionCall.name || '',\n                  model,\n                  timestamp,\n                  index: nextToolIndex - 1,\n                }\n\n                // Emit TOOL_CALL_END with parsed input\n                let parsedInput: unknown = {}\n                try {\n                  parsedInput =\n                    typeof functionArgs === 'string'\n                      ? JSON.parse(functionArgs)\n                      : functionArgs\n                } catch {\n                  parsedInput = {}\n                }\n\n                yield {\n                  type: 'TOOL_CALL_END',\n                  toolCallId,\n                  toolName: functionCall.name || '',\n                  model,\n                  timestamp,\n                  input: parsedInput,\n                }\n              }\n            }\n          }\n        }\n\n        // Emit TOOL_CALL_END for all tracked tool calls\n        for (const [toolCallId, toolCallData] of toolCallMap.entries()) {\n          let parsedInput: unknown = {}\n          try {\n            parsedInput = JSON.parse(toolCallData.args)\n          } catch {\n            parsedInput = {}\n          }\n\n          yield {\n            type: 'TOOL_CALL_END',\n            toolCallId,\n            toolName: toolCallData.name,\n            model,\n            timestamp,\n            input: parsedInput,\n          }\n        }\n\n        // Reset so a new TEXT_MESSAGE_START is emitted if text follows tool calls\n        if (toolCallMap.size > 0) {\n          hasEmittedTextMessageStart = false\n        }\n\n        if (finishReason === FinishReason.MAX_TOKENS) {\n          yield {\n            type: 'RUN_ERROR',\n            runId,\n            model,\n            timestamp,\n            error: {\n              message:\n                'The response was cut off because the maximum token limit was reached.',\n              code: 'max_tokens',\n            },\n          }\n        }\n\n        // Emit TEXT_MESSAGE_END if we had text content\n        if (hasEmittedTextMessageStart) {\n          yield {\n            type: 'TEXT_MESSAGE_END',\n            messageId,\n            model,\n            timestamp,\n          }\n        }\n\n        yield {\n          type: 'RUN_FINISHED',\n          runId,\n          model,\n          timestamp,\n          finishReason: toolCallMap.size > 0 ? 'tool_calls' : 'stop',\n          usage: chunk.usageMetadata\n            ? {\n                promptTokens: chunk.usageMetadata.promptTokenCount ?? 0,\n                completionTokens: chunk.usageMetadata.candidatesTokenCount ?? 0,\n                totalTokens: chunk.usageMetadata.totalTokenCount ?? 0,\n              }\n            : undefined,\n        }\n      }\n    }\n  }\n\n  private convertContentPartToGemini(part: ContentPart): Part {\n    switch (part.type) {\n      case 'text':\n        return { text: part.content }\n      case 'image':\n      case 'audio':\n      case 'video':\n      case 'document': {\n        if (part.source.type === 'data') {\n          return {\n            inlineData: {\n              data: part.source.value,\n              mimeType: part.source.mimeType,\n            },\n          }\n        } else {\n          // For URL sources, use provided mimeType or fall back to reasonable defaults\n          const defaultMimeType = {\n            image: 'image/jpeg',\n            audio: 'audio/mp3',\n            video: 'video/mp4',\n            document: 'application/pdf',\n          }[part.type]\n\n          return {\n            fileData: {\n              fileUri: part.source.value,\n              mimeType: part.source.mimeType ?? defaultMimeType,\n            },\n          }\n        }\n      }\n      default: {\n        const _exhaustiveCheck: never = part\n        throw new Error(\n          `Unsupported content part type: ${(_exhaustiveCheck as ContentPart).type}`,\n        )\n      }\n    }\n  }\n\n  private formatMessages(\n    messages: Array<ModelMessage>,\n  ): GenerateContentParameters['contents'] {\n    const formatted = messages.map((msg) => {\n      const role: 'user' | 'model' = msg.role === 'assistant' ? 'model' : 'user'\n      const parts: Array<Part> = []\n\n      if (Array.isArray(msg.content)) {\n        for (const contentPart of msg.content) {\n          parts.push(this.convertContentPartToGemini(contentPart))\n        }\n      } else if (msg.content) {\n        parts.push({ text: msg.content })\n      }\n\n      if (msg.role === 'assistant' && msg.toolCalls?.length) {\n        for (const toolCall of msg.toolCalls) {\n          let parsedArgs: Record<string, unknown> = {}\n          try {\n            parsedArgs = toolCall.function.arguments\n              ? (JSON.parse(toolCall.function.arguments) as Record<\n                  string,\n                  unknown\n                >)\n              : {}\n          } catch {\n            parsedArgs = toolCall.function.arguments as unknown as Record<\n              string,\n              unknown\n            >\n          }\n\n          parts.push({\n            functionCall: {\n              name: toolCall.function.name,\n              args: parsedArgs,\n            },\n          })\n        }\n      }\n\n      if (msg.role === 'tool' && msg.toolCallId) {\n        parts.push({\n          functionResponse: {\n            name: msg.toolCallId,\n            response: {\n              content: msg.content || '',\n            },\n          },\n        })\n      }\n\n      return {\n        role,\n        parts: parts.length > 0 ? parts : [{ text: '' }],\n      }\n    })\n\n    // Post-process: Gemini requires strictly alternating user/model roles.\n    // Tool results are mapped to role:'user', which can create consecutive\n    // user messages when followed by a new user message. Merge them.\n    return this.mergeConsecutiveSameRoleMessages(formatted)\n  }\n\n  /**\n   * Merge consecutive messages of the same role into a single message.\n   * Gemini's API requires strictly alternating user/model roles.\n   * Tool results are mapped to role:'user', which can collide with actual\n   * user messages in multi-turn conversations.\n   *\n   * Also filters out empty model messages (e.g., from a previous failed request)\n   * and deduplicates functionResponse parts with the same name (tool call ID).\n   */\n  private mergeConsecutiveSameRoleMessages(\n    messages: Array<Content>,\n  ): Array<Content> {\n    const merged: Array<Content> = []\n\n    for (const msg of messages) {\n      const parts = msg.parts || []\n\n      // Skip empty model messages (no parts or only empty text)\n      if (msg.role === 'model') {\n        const hasContent =\n          parts.length > 0 &&\n          !parts.every(\n            (p) => 'text' in p && (p as { text: string }).text === '',\n          )\n        if (!hasContent) {\n          continue\n        }\n      }\n\n      const prev = merged[merged.length - 1]\n      if (prev && prev.role === msg.role) {\n        // Merge parts arrays\n        prev.parts = [...(prev.parts || []), ...parts]\n      } else {\n        merged.push({ ...msg, parts: [...parts] })\n      }\n    }\n\n    // Deduplicate functionResponse parts with the same name (tool call ID)\n    for (const msg of merged) {\n      if (!msg.parts) continue\n      const seenFunctionResponseNames = new Set<string>()\n      msg.parts = msg.parts.filter((part) => {\n        if ('functionResponse' in part && part.functionResponse?.name) {\n          if (seenFunctionResponseNames.has(part.functionResponse.name)) {\n            return false\n          }\n          seenFunctionResponseNames.add(part.functionResponse.name)\n        }\n        return true\n      })\n    }\n\n    return merged\n  }\n\n  private mapCommonOptionsToGemini(\n    options: TextOptions<GeminiTextProviderOptions>,\n  ) {\n    const modelOpts = options.modelOptions\n    const thinkingConfig = modelOpts?.thinkingConfig\n    const requestOptions: GenerateContentParameters = {\n      model: options.model,\n      contents: this.formatMessages(options.messages),\n      config: {\n        ...modelOpts,\n        temperature: options.temperature,\n        topP: options.topP,\n        maxOutputTokens: options.maxTokens,\n        thinkingConfig: thinkingConfig\n          ? {\n              ...thinkingConfig,\n              thinkingLevel: thinkingConfig.thinkingLevel\n                ? // Enum is provided by the SDK, we use it for the type but cast it to string constants, here we just cast them back\n                  (thinkingConfig.thinkingLevel as ThinkingLevel)\n                : undefined,\n            }\n          : undefined,\n        systemInstruction: options.systemPrompts?.join('\\n'),\n        tools: convertToolsToProviderFormat(options.tools),\n      },\n    }\n\n    return requestOptions\n  }\n}\n\n/**\n * Creates a Gemini text adapter with explicit API key.\n * Type resolution happens here at the call site.\n */\nexport function createGeminiChat<TModel extends (typeof GEMINI_MODELS)[number]>(\n  model: TModel,\n  apiKey: string,\n  config?: Omit<GeminiTextConfig, 'apiKey'>,\n): GeminiTextAdapter<\n  TModel,\n  ResolveProviderOptions<TModel>,\n  ResolveInputModalities<TModel>\n> {\n  return new GeminiTextAdapter({ apiKey, ...config }, model)\n}\n\n/**\n * Creates a Gemini text adapter with automatic API key detection.\n * Type resolution happens here at the call site.\n */\nexport function geminiText<TModel extends (typeof GEMINI_MODELS)[number]>(\n  model: TModel,\n  config?: Omit<GeminiTextConfig, 'apiKey'>,\n): GeminiTextAdapter<\n  TModel,\n  ResolveProviderOptions<TModel>,\n  ResolveInputModalities<TModel>\n> {\n  const apiKey = getGeminiApiKeyFromEnv()\n  return createGeminiChat(model, apiKey, config)\n}\n"],"names":[],"mappings":";;;;AA8EO,MAAM,0BAKH,gBAKR;AAAA,EAMA,YAAY,QAA0B,OAAe;AACnD,UAAM,CAAA,GAAI,KAAK;AANjB,SAAS,OAAO;AAChB,SAAS,OAAO;AAMd,SAAK,SAAS,mBAAmB,MAAM;AAAA,EACzC;AAAA,EAEA,OAAO,WACL,SAC4B;AAC5B,UAAM,gBAAgB,KAAK,yBAAyB,OAAO;AAE3D,QAAI;AACF,YAAM,SACJ,MAAM,KAAK,OAAO,OAAO,sBAAsB,aAAa;AAE9D,aAAO,KAAK,oBAAoB,QAAQ,QAAQ,KAAK;AAAA,IACvD,SAAS,OAAO;AACd,YAAM,YAAY,KAAK,IAAA;AACvB,YAAM;AAAA,QACJ,MAAM;AAAA,QACN,OAAO,QAAQ;AAAA,QACf;AAAA,QACA,OAAO;AAAA,UACL,SACE,iBAAiB,QACb,MAAM,UACN;AAAA,QAAA;AAAA,MACR;AAAA,IAEJ;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,iBACJ,SAC0C;AAC1C,UAAM,EAAE,aAAa,aAAA,IAAiB;AAEtC,UAAM,gBAAgB,KAAK,yBAAyB,WAAW;AAE/D,QAAI;AAEF,YAAM,SAAS,MAAM,KAAK,OAAO,OAAO,gBAAgB;AAAA,QACtD,GAAG;AAAA,QACH,QAAQ;AAAA,UACN,GAAG,cAAc;AAAA,UACjB,kBAAkB;AAAA,UAClB,gBAAgB;AAAA,QAAA;AAAA,MAClB,CACD;AAGD,YAAM,UAAU,KAAK,wBAAwB,MAAM;AAGnD,UAAI;AACJ,UAAI;AACF,iBAAS,KAAK,MAAM,OAAO;AAAA,MAC7B,QAAQ;AACN,cAAM,IAAI;AAAA,UACR,uDAAuD,QAAQ,MAAM,GAAG,GAAG,CAAC,GAAG,QAAQ,SAAS,MAAM,QAAQ,EAAE;AAAA,QAAA;AAAA,MAEpH;AAEA,aAAO;AAAA,QACL,MAAM;AAAA,QACN;AAAA,MAAA;AAAA,IAEJ,SAAS,OAAO;AACd,YAAM,IAAI;AAAA,QACR,iBAAiB,QACb,MAAM,UACN;AAAA,MAAA;AAAA,IAER;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKQ,wBAAwB,UAA2C;AACzE,QAAI,cAAc;AAElB,QAAI,SAAS,aAAa,CAAC,GAAG,SAAS,OAAO;AAC5C,iBAAW,QAAQ,SAAS,WAAW,CAAC,EAAE,QAAQ,OAAO;AACvD,YAAI,KAAK,MAAM;AACb,yBAAe,KAAK;AAAA,QACtB;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,OAAe,oBACb,QACA,OAC4B;AAC5B,UAAM,YAAY,KAAK,IAAA;AACvB,QAAI,qBAAqB;AACzB,QAAI,sBAAsB;AAC1B,UAAM,kCAAkB,IAAA;AAIxB,QAAI,gBAAgB;AAGpB,UAAM,QAAQ,WAAW,KAAK,IAAI;AAClC,UAAM,YAAY,WAAW,KAAK,IAAI;AACtC,QAAI,SAAwB;AAC5B,QAAI,uBAAuB;AAC3B,QAAI,6BAA6B;AACjC,QAAI,wBAAwB;AAE5B,qBAAiB,SAAS,QAAQ;AAEhC,UAAI,CAAC,sBAAsB;AACzB,+BAAuB;AACvB,cAAM;AAAA,UACJ,MAAM;AAAA,UACN;AAAA,UACA;AAAA,UACA;AAAA,QAAA;AAAA,MAEJ;AAEA,UAAI,MAAM,aAAa,CAAC,GAAG,SAAS,OAAO;AACzC,cAAM,QAAQ,MAAM,WAAW,CAAC,EAAE,QAAQ;AAE1C,mBAAW,QAAQ,OAAO;AACxB,cAAI,KAAK,MAAM;AACb,gBAAI,KAAK,SAAS;AAEhB,kBAAI,CAAC,uBAAuB;AAC1B,wCAAwB;AACxB,yBAAS,WAAW,KAAK,IAAI;AAC7B,sBAAM;AAAA,kBACJ,MAAM;AAAA,kBACN;AAAA,kBACA;AAAA,kBACA;AAAA,kBACA,UAAU;AAAA,gBAAA;AAAA,cAEd;AAEA,qCAAuB,KAAK;AAC5B,oBAAM;AAAA,gBACJ,MAAM;AAAA,gBACN,QAAQ,UAAU,WAAW,KAAK,IAAI;AAAA,gBACtC;AAAA,gBACA;AAAA,gBACA,OAAO,KAAK;AAAA,gBACZ,SAAS;AAAA,cAAA;AAAA,YAEb,WAAW,KAAK,KAAK,KAAA,GAAQ;AAG3B,kBAAI,CAAC,4BAA4B;AAC/B,6CAA6B;AAC7B,sBAAM;AAAA,kBACJ,MAAM;AAAA,kBACN;AAAA,kBACA;AAAA,kBACA;AAAA,kBACA,MAAM;AAAA,gBAAA;AAAA,cAEV;AAEA,oCAAsB,KAAK;AAC3B,oBAAM;AAAA,gBACJ,MAAM;AAAA,gBACN;AAAA,gBACA;AAAA,gBACA;AAAA,gBACA,OAAO,KAAK;AAAA,gBACZ,SAAS;AAAA,cAAA;AAAA,YAEb;AAAA,UACF;AAEA,gBAAM,eAAe,KAAK;AAC1B,cAAI,cAAc;AAChB,kBAAM,aACJ,aAAa,MACb,GAAG,aAAa,IAAI,IAAI,KAAK,IAAA,CAAK,IAAI,aAAa;AACrD,kBAAM,eAAe,aAAa,QAAQ,CAAA;AAE1C,gBAAI,eAAe,YAAY,IAAI,UAAU;AAC7C,gBAAI,CAAC,cAAc;AACjB,6BAAe;AAAA,gBACb,MAAM,aAAa,QAAQ;AAAA,gBAC3B,MACE,OAAO,iBAAiB,WACpB,eACA,KAAK,UAAU,YAAY;AAAA,gBACjC,OAAO;AAAA,gBACP,SAAS;AAAA,cAAA;AAEX,0BAAY,IAAI,YAAY,YAAY;AAAA,YAC1C,OAAO;AACL,kBAAI;AACF,sBAAM,eAAe,KAAK,MAAM,aAAa,IAAI;AACjD,sBAAM,UACJ,OAAO,iBAAiB,WACpB,KAAK,MAAM,YAAY,IACvB;AACN,sBAAM,aAAa,EAAE,GAAG,cAAc,GAAG,QAAA;AACzC,6BAAa,OAAO,KAAK,UAAU,UAAU;AAAA,cAC/C,QAAQ;AACN,6BAAa,OACX,OAAO,iBAAiB,WACpB,eACA,KAAK,UAAU,YAAY;AAAA,cACnC;AAAA,YACF;AAGA,gBAAI,CAAC,aAAa,SAAS;AACzB,2BAAa,UAAU;AACvB,oBAAM;AAAA,gBACJ,MAAM;AAAA,gBACN;AAAA,gBACA,UAAU,aAAa;AAAA,gBACvB;AAAA,gBACA;AAAA,gBACA,OAAO,aAAa;AAAA,cAAA;AAAA,YAExB;AAGA,kBAAM;AAAA,cACJ,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA;AAAA,cACA,OAAO,aAAa;AAAA,cACpB,MAAM,aAAa;AAAA,YAAA;AAAA,UAEvB;AAAA,QACF;AAAA,MACF,WAAW,MAAM,QAAQ,MAAM,KAAK,QAAQ;AAG1C,YAAI,CAAC,4BAA4B;AAC/B,uCAA6B;AAC7B,gBAAM;AAAA,YACJ,MAAM;AAAA,YACN;AAAA,YACA;AAAA,YACA;AAAA,YACA,MAAM;AAAA,UAAA;AAAA,QAEV;AAEA,8BAAsB,MAAM;AAC5B,cAAM;AAAA,UACJ,MAAM;AAAA,UACN;AAAA,UACA;AAAA,UACA;AAAA,UACA,OAAO,MAAM;AAAA,UACb,SAAS;AAAA,QAAA;AAAA,MAEb;AAEA,UAAI,MAAM,aAAa,CAAC,GAAG,cAAc;AACvC,cAAM,eAAe,MAAM,WAAW,CAAC,EAAE;AAEzC,YAAI,iBAAiB,aAAa,sBAAsB;AACtD,cAAI,MAAM,WAAW,CAAC,EAAE,SAAS,OAAO;AACtC,uBAAW,QAAQ,MAAM,WAAW,CAAC,EAAE,QAAQ,OAAO;AACpD,oBAAM,eAAe,KAAK;AAC1B,kBAAI,cAAc;AAChB,sBAAM,aACJ,aAAa,MACb,GAAG,aAAa,IAAI,IAAI,KAAK,IAAA,CAAK,IAAI,aAAa;AACrD,sBAAM,eAAe,aAAa,QAAQ,CAAA;AAE1C,sBAAM,aACJ,OAAO,iBAAiB,WACpB,eACA,KAAK,UAAU,YAAY;AAEjC,4BAAY,IAAI,YAAY;AAAA,kBAC1B,MAAM,aAAa,QAAQ;AAAA,kBAC3B,MAAM;AAAA,kBACN,OAAO;AAAA,kBACP,SAAS;AAAA,gBAAA,CACV;AAGD,sBAAM;AAAA,kBACJ,MAAM;AAAA,kBACN;AAAA,kBACA,UAAU,aAAa,QAAQ;AAAA,kBAC/B;AAAA,kBACA;AAAA,kBACA,OAAO,gBAAgB;AAAA,gBAAA;AAIzB,oBAAI,cAAuB,CAAA;AAC3B,oBAAI;AACF,gCACE,OAAO,iBAAiB,WACpB,KAAK,MAAM,YAAY,IACvB;AAAA,gBACR,QAAQ;AACN,gCAAc,CAAA;AAAA,gBAChB;AAEA,sBAAM;AAAA,kBACJ,MAAM;AAAA,kBACN;AAAA,kBACA,UAAU,aAAa,QAAQ;AAAA,kBAC/B;AAAA,kBACA;AAAA,kBACA,OAAO;AAAA,gBAAA;AAAA,cAEX;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAGA,mBAAW,CAAC,YAAY,YAAY,KAAK,YAAY,WAAW;AAC9D,cAAI,cAAuB,CAAA;AAC3B,cAAI;AACF,0BAAc,KAAK,MAAM,aAAa,IAAI;AAAA,UAC5C,QAAQ;AACN,0BAAc,CAAA;AAAA,UAChB;AAEA,gBAAM;AAAA,YACJ,MAAM;AAAA,YACN;AAAA,YACA,UAAU,aAAa;AAAA,YACvB;AAAA,YACA;AAAA,YACA,OAAO;AAAA,UAAA;AAAA,QAEX;AAGA,YAAI,YAAY,OAAO,GAAG;AACxB,uCAA6B;AAAA,QAC/B;AAEA,YAAI,iBAAiB,aAAa,YAAY;AAC5C,gBAAM;AAAA,YACJ,MAAM;AAAA,YACN;AAAA,YACA;AAAA,YACA;AAAA,YACA,OAAO;AAAA,cACL,SACE;AAAA,cACF,MAAM;AAAA,YAAA;AAAA,UACR;AAAA,QAEJ;AAGA,YAAI,4BAA4B;AAC9B,gBAAM;AAAA,YACJ,MAAM;AAAA,YACN;AAAA,YACA;AAAA,YACA;AAAA,UAAA;AAAA,QAEJ;AAEA,cAAM;AAAA,UACJ,MAAM;AAAA,UACN;AAAA,UACA;AAAA,UACA;AAAA,UACA,cAAc,YAAY,OAAO,IAAI,eAAe;AAAA,UACpD,OAAO,MAAM,gBACT;AAAA,YACE,cAAc,MAAM,cAAc,oBAAoB;AAAA,YACtD,kBAAkB,MAAM,cAAc,wBAAwB;AAAA,YAC9D,aAAa,MAAM,cAAc,mBAAmB;AAAA,UAAA,IAEtD;AAAA,QAAA;AAAA,MAER;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,2BAA2B,MAAyB;AAC1D,YAAQ,KAAK,MAAA;AAAA,MACX,KAAK;AACH,eAAO,EAAE,MAAM,KAAK,QAAA;AAAA,MACtB,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK,YAAY;AACf,YAAI,KAAK,OAAO,SAAS,QAAQ;AAC/B,iBAAO;AAAA,YACL,YAAY;AAAA,cACV,MAAM,KAAK,OAAO;AAAA,cAClB,UAAU,KAAK,OAAO;AAAA,YAAA;AAAA,UACxB;AAAA,QAEJ,OAAO;AAEL,gBAAM,kBAAkB;AAAA,YACtB,OAAO;AAAA,YACP,OAAO;AAAA,YACP,OAAO;AAAA,YACP,UAAU;AAAA,UAAA,EACV,KAAK,IAAI;AAEX,iBAAO;AAAA,YACL,UAAU;AAAA,cACR,SAAS,KAAK,OAAO;AAAA,cACrB,UAAU,KAAK,OAAO,YAAY;AAAA,YAAA;AAAA,UACpC;AAAA,QAEJ;AAAA,MACF;AAAA,MACA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI;AAAA,UACR,kCAAmC,iBAAiC,IAAI;AAAA,QAAA;AAAA,MAE5E;AAAA,IAAA;AAAA,EAEJ;AAAA,EAEQ,eACN,UACuC;AACvC,UAAM,YAAY,SAAS,IAAI,CAAC,QAAQ;AACtC,YAAM,OAAyB,IAAI,SAAS,cAAc,UAAU;AACpE,YAAM,QAAqB,CAAA;AAE3B,UAAI,MAAM,QAAQ,IAAI,OAAO,GAAG;AAC9B,mBAAW,eAAe,IAAI,SAAS;AACrC,gBAAM,KAAK,KAAK,2BAA2B,WAAW,CAAC;AAAA,QACzD;AAAA,MACF,WAAW,IAAI,SAAS;AACtB,cAAM,KAAK,EAAE,MAAM,IAAI,SAAS;AAAA,MAClC;AAEA,UAAI,IAAI,SAAS,eAAe,IAAI,WAAW,QAAQ;AACrD,mBAAW,YAAY,IAAI,WAAW;AACpC,cAAI,aAAsC,CAAA;AAC1C,cAAI;AACF,yBAAa,SAAS,SAAS,YAC1B,KAAK,MAAM,SAAS,SAAS,SAAS,IAIvC,CAAA;AAAA,UACN,QAAQ;AACN,yBAAa,SAAS,SAAS;AAAA,UAIjC;AAEA,gBAAM,KAAK;AAAA,YACT,cAAc;AAAA,cACZ,MAAM,SAAS,SAAS;AAAA,cACxB,MAAM;AAAA,YAAA;AAAA,UACR,CACD;AAAA,QACH;AAAA,MACF;AAEA,UAAI,IAAI,SAAS,UAAU,IAAI,YAAY;AACzC,cAAM,KAAK;AAAA,UACT,kBAAkB;AAAA,YAChB,MAAM,IAAI;AAAA,YACV,UAAU;AAAA,cACR,SAAS,IAAI,WAAW;AAAA,YAAA;AAAA,UAC1B;AAAA,QACF,CACD;AAAA,MACH;AAEA,aAAO;AAAA,QACL;AAAA,QACA,OAAO,MAAM,SAAS,IAAI,QAAQ,CAAC,EAAE,MAAM,GAAA,CAAI;AAAA,MAAA;AAAA,IAEnD,CAAC;AAKD,WAAO,KAAK,iCAAiC,SAAS;AAAA,EACxD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWQ,iCACN,UACgB;AAChB,UAAM,SAAyB,CAAA;AAE/B,eAAW,OAAO,UAAU;AAC1B,YAAM,QAAQ,IAAI,SAAS,CAAA;AAG3B,UAAI,IAAI,SAAS,SAAS;AACxB,cAAM,aACJ,MAAM,SAAS,KACf,CAAC,MAAM;AAAA,UACL,CAAC,MAAM,UAAU,KAAM,EAAuB,SAAS;AAAA,QAAA;AAE3D,YAAI,CAAC,YAAY;AACf;AAAA,QACF;AAAA,MACF;AAEA,YAAM,OAAO,OAAO,OAAO,SAAS,CAAC;AACrC,UAAI,QAAQ,KAAK,SAAS,IAAI,MAAM;AAElC,aAAK,QAAQ,CAAC,GAAI,KAAK,SAAS,CAAA,GAAK,GAAG,KAAK;AAAA,MAC/C,OAAO;AACL,eAAO,KAAK,EAAE,GAAG,KAAK,OAAO,CAAC,GAAG,KAAK,GAAG;AAAA,MAC3C;AAAA,IACF;AAGA,eAAW,OAAO,QAAQ;AACxB,UAAI,CAAC,IAAI,MAAO;AAChB,YAAM,gDAAgC,IAAA;AACtC,UAAI,QAAQ,IAAI,MAAM,OAAO,CAAC,SAAS;AACrC,YAAI,sBAAsB,QAAQ,KAAK,kBAAkB,MAAM;AAC7D,cAAI,0BAA0B,IAAI,KAAK,iBAAiB,IAAI,GAAG;AAC7D,mBAAO;AAAA,UACT;AACA,oCAA0B,IAAI,KAAK,iBAAiB,IAAI;AAAA,QAC1D;AACA,eAAO;AAAA,MACT,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,EACT;AAAA,EAEQ,yBACN,SACA;AACA,UAAM,YAAY,QAAQ;AAC1B,UAAM,iBAAiB,WAAW;AAClC,UAAM,iBAA4C;AAAA,MAChD,OAAO,QAAQ;AAAA,MACf,UAAU,KAAK,eAAe,QAAQ,QAAQ;AAAA,MAC9C,QAAQ;AAAA,QACN,GAAG;AAAA,QACH,aAAa,QAAQ;AAAA,QACrB,MAAM,QAAQ;AAAA,QACd,iBAAiB,QAAQ;AAAA,QACzB,gBAAgB,iBACZ;AAAA,UACE,GAAG;AAAA,UACH,eAAe,eAAe;AAAA;AAAA,YAEzB,eAAe;AAAA,cAChB;AAAA,QAAA,IAEN;AAAA,QACJ,mBAAmB,QAAQ,eAAe,KAAK,IAAI;AAAA,QACnD,OAAO,6BAA6B,QAAQ,KAAK;AAAA,MAAA;AAAA,IACnD;AAGF,WAAO;AAAA,EACT;AACF;AAMO,SAAS,iBACd,OACA,QACA,QAKA;AACA,SAAO,IAAI,kBAAkB,EAAE,QAAQ,GAAG,OAAA,GAAU,KAAK;AAC3D;AAMO,SAAS,WACd,OACA,QAKA;AACA,QAAM,SAAS,uBAAA;AACf,SAAO,iBAAiB,OAAO,QAAQ,MAAM;AAC/C;"}