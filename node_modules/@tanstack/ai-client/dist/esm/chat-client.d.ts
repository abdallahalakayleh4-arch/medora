import { AnyClientTool, ModelMessage, StreamChunk } from '@tanstack/ai';
import { ConnectionAdapter } from './connection-adapters.js';
import { ChatClientOptions, ChatClientState, MultimodalContent, UIMessage } from './types.js';
export declare class ChatClient {
    private processor;
    private connection;
    private uniqueId;
    private body;
    private pendingMessageBody;
    private isLoading;
    private error;
    private status;
    private abortController;
    private events;
    private clientToolsRef;
    private currentStreamId;
    private currentMessageId;
    private postStreamActions;
    private pendingToolExecutions;
    private continuationPending;
    private callbacksRef;
    constructor(options: ChatClientOptions);
    private generateUniqueId;
    private setIsLoading;
    private setStatus;
    private setError;
    /**
     * Process a stream through the StreamProcessor
     */
    private processStream;
    /**
     * Send a message and stream the response.
     * Supports both simple string content and multimodal content (images, audio, video, documents).
     *
     * @param content - The message content. Can be:
     *   - A simple string for text-only messages
     *   - A MultimodalContent object with content array and optional custom ID
     * @param body - Optional body parameters to merge with the client's base body for this request.
     *               Uses shallow merge with per-message body taking priority.
     *
     * @example
     * ```ts
     * // Simple text message
     * await client.sendMessage('Hello!')
     *
     * // Text message with custom body params
     * await client.sendMessage('Hello!', { temperature: 0.7 })
     *
     * // Multimodal message with image
     * await client.sendMessage({
     *   content: [
     *     { type: 'text', content: 'What is in this image?' },
     *     { type: 'image', source: { type: 'url', value: 'https://example.com/photo.jpg' } }
     *   ]
     * })
     *
     * // Multimodal message with custom ID and body params
     * await client.sendMessage(
     *   {
     *     content: [
     *       { type: 'text', content: 'Describe this audio' },
     *       { type: 'audio', source: { type: 'data', value: 'base64...' } }
     *     ],
     *     id: 'custom-message-id'
     *   },
     *   { model: 'gpt-4-audio' }
     * )
     * ```
     */
    sendMessage(content: string | MultimodalContent, body?: Record<string, any>): Promise<void>;
    /**
     * Normalize the message input to extract content and optional id.
     * Trims string content automatically.
     */
    private normalizeMessageInput;
    /**
     * Append a message and stream the response
     */
    append(message: UIMessage | ModelMessage): Promise<void>;
    /**
     * Stream a response from the LLM
     */
    private streamResponse;
    /**
     * Reload the last assistant message
     */
    reload(): Promise<void>;
    /**
     * Stop the current stream
     */
    stop(): void;
    /**
     * Clear all messages
     */
    clear(): void;
    /**
     * Add the result of a client-side tool execution
     */
    addToolResult(result: {
        toolCallId: string;
        tool: string;
        output: any;
        state?: 'output-available' | 'output-error';
        errorText?: string;
    }): Promise<void>;
    /**
     * Respond to a tool approval request
     */
    addToolApprovalResponse(response: {
        id: string;
        approved: boolean;
    }): Promise<void>;
    /**
     * Queue an action to be executed after the current stream ends
     */
    private queuePostStreamAction;
    /**
     * Drain and execute all queued post-stream actions
     */
    private drainPostStreamActions;
    /**
     * Check if we should continue the flow and do so if needed
     */
    private checkForContinuation;
    /**
     * Check if all tool calls are complete and we should auto-send
     */
    private shouldAutoSend;
    /**
     * Get current messages
     */
    getMessages(): Array<UIMessage>;
    /**
     * Get loading state
     */
    getIsLoading(): boolean;
    /**
     * Get current status
     */
    getStatus(): ChatClientState;
    /**
     * Get current error
     */
    getError(): Error | undefined;
    /**
     * Manually set messages
     */
    setMessagesManually(messages: Array<UIMessage>): void;
    /**
     * Update options refs (for use in React hooks to avoid recreating client)
     */
    updateOptions(options: {
        connection?: ConnectionAdapter;
        body?: Record<string, any>;
        tools?: ReadonlyArray<AnyClientTool>;
        onResponse?: (response?: Response) => void | Promise<void>;
        onChunk?: (chunk: StreamChunk) => void;
        onFinish?: (message: UIMessage) => void;
        onError?: (error: Error) => void;
    }): void;
}
