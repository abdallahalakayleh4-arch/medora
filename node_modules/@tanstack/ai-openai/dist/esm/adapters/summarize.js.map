{"version":3,"file":"summarize.js","sources":["../../../src/adapters/summarize.ts"],"sourcesContent":["import { BaseSummarizeAdapter } from '@tanstack/ai/adapters'\nimport { getOpenAIApiKeyFromEnv } from '../utils/client'\nimport { OpenAITextAdapter } from './text'\nimport type { OpenAIChatModel } from '../model-meta'\nimport type {\n  StreamChunk,\n  SummarizationOptions,\n  SummarizationResult,\n} from '@tanstack/ai'\nimport type { OpenAIClientConfig } from '../utils/client'\n\n/**\n * Configuration for OpenAI summarize adapter\n */\nexport interface OpenAISummarizeConfig extends OpenAIClientConfig {}\n\n/**\n * OpenAI-specific provider options for summarization\n */\nexport interface OpenAISummarizeProviderOptions {\n  /** Temperature for response generation (0-2) */\n  temperature?: number\n  /** Maximum tokens in the response */\n  maxTokens?: number\n}\n\n/**\n * OpenAI Summarize Adapter\n *\n * A thin wrapper around the text adapter that adds summarization-specific prompting.\n * Delegates all API calls to the OpenAITextAdapter.\n */\nexport class OpenAISummarizeAdapter<\n  TModel extends OpenAIChatModel,\n> extends BaseSummarizeAdapter<TModel, OpenAISummarizeProviderOptions> {\n  readonly kind = 'summarize' as const\n  readonly name = 'openai' as const\n\n  private textAdapter: OpenAITextAdapter<TModel>\n\n  constructor(config: OpenAISummarizeConfig, model: TModel) {\n    super({}, model)\n    this.textAdapter = new OpenAITextAdapter(config, model)\n  }\n\n  async summarize(options: SummarizationOptions): Promise<SummarizationResult> {\n    const systemPrompt = this.buildSummarizationPrompt(options)\n\n    // Use the text adapter's streaming and collect the result\n    let summary = ''\n    const id = ''\n    let model = options.model\n    let usage = { promptTokens: 0, completionTokens: 0, totalTokens: 0 }\n\n    for await (const chunk of this.textAdapter.chatStream({\n      model: options.model,\n      messages: [{ role: 'user', content: options.text }],\n      systemPrompts: [systemPrompt],\n      maxTokens: options.maxLength,\n      temperature: 0.3,\n    })) {\n      // AG-UI TEXT_MESSAGE_CONTENT event\n      if (chunk.type === 'TEXT_MESSAGE_CONTENT') {\n        if (chunk.content) {\n          summary = chunk.content\n        } else {\n          summary += chunk.delta\n        }\n        model = chunk.model || model\n      }\n      // AG-UI RUN_FINISHED event\n      if (chunk.type === 'RUN_FINISHED') {\n        if (chunk.usage) {\n          usage = chunk.usage\n        }\n      }\n    }\n\n    return { id, model, summary, usage }\n  }\n\n  async *summarizeStream(\n    options: SummarizationOptions,\n  ): AsyncIterable<StreamChunk> {\n    const systemPrompt = this.buildSummarizationPrompt(options)\n\n    // Delegate directly to the text adapter's streaming\n    yield* this.textAdapter.chatStream({\n      model: options.model,\n      messages: [{ role: 'user', content: options.text }],\n      systemPrompts: [systemPrompt],\n      maxTokens: options.maxLength,\n      temperature: 0.3,\n    })\n  }\n\n  private buildSummarizationPrompt(options: SummarizationOptions): string {\n    let prompt = 'You are a professional summarizer. '\n\n    switch (options.style) {\n      case 'bullet-points':\n        prompt += 'Provide a summary in bullet point format. '\n        break\n      case 'paragraph':\n        prompt += 'Provide a summary in paragraph format. '\n        break\n      case 'concise':\n        prompt += 'Provide a very concise summary in 1-2 sentences. '\n        break\n      default:\n        prompt += 'Provide a clear and concise summary. '\n    }\n\n    if (options.focus && options.focus.length > 0) {\n      prompt += `Focus on the following aspects: ${options.focus.join(', ')}. `\n    }\n\n    if (options.maxLength) {\n      prompt += `Keep the summary under ${options.maxLength} tokens. `\n    }\n\n    return prompt\n  }\n}\n\n/**\n * Creates an OpenAI summarize adapter with explicit API key.\n * Type resolution happens here at the call site.\n *\n * @param model - The model name (e.g., 'gpt-4o-mini', 'gpt-4o')\n * @param apiKey - Your OpenAI API key\n * @param config - Optional additional configuration\n * @returns Configured OpenAI summarize adapter instance with resolved types\n *\n * @example\n * ```typescript\n * const adapter = createOpenaiSummarize('gpt-4o-mini', \"sk-...\");\n * ```\n */\nexport function createOpenaiSummarize<TModel extends OpenAIChatModel>(\n  model: TModel,\n  apiKey: string,\n  config?: Omit<OpenAISummarizeConfig, 'apiKey'>,\n): OpenAISummarizeAdapter<TModel> {\n  return new OpenAISummarizeAdapter({ apiKey, ...config }, model)\n}\n\n/**\n * Creates an OpenAI summarize adapter with automatic API key detection from environment variables.\n * Type resolution happens here at the call site.\n *\n * Looks for `OPENAI_API_KEY` in:\n * - `process.env` (Node.js)\n * - `window.env` (Browser with injected env)\n *\n * @param model - The model name (e.g., 'gpt-4o-mini', 'gpt-4o')\n * @param config - Optional configuration (excluding apiKey which is auto-detected)\n * @returns Configured OpenAI summarize adapter instance with resolved types\n * @throws Error if OPENAI_API_KEY is not found in environment\n *\n * @example\n * ```typescript\n * // Automatically uses OPENAI_API_KEY from environment\n * const adapter = openaiSummarize('gpt-4o-mini');\n *\n * await summarize({\n *   adapter,\n *   text: \"Long article text...\"\n * });\n * ```\n */\nexport function openaiSummarize<TModel extends OpenAIChatModel>(\n  model: TModel,\n  config?: Omit<OpenAISummarizeConfig, 'apiKey'>,\n): OpenAISummarizeAdapter<TModel> {\n  const apiKey = getOpenAIApiKeyFromEnv()\n  return createOpenaiSummarize(model, apiKey, config)\n}\n"],"names":[],"mappings":";;;AAgCO,MAAM,+BAEH,qBAA6D;AAAA,EAMrE,YAAY,QAA+B,OAAe;AACxD,UAAM,CAAA,GAAI,KAAK;AANjB,SAAS,OAAO;AAChB,SAAS,OAAO;AAMd,SAAK,cAAc,IAAI,kBAAkB,QAAQ,KAAK;AAAA,EACxD;AAAA,EAEA,MAAM,UAAU,SAA6D;AAC3E,UAAM,eAAe,KAAK,yBAAyB,OAAO;AAG1D,QAAI,UAAU;AACd,UAAM,KAAK;AACX,QAAI,QAAQ,QAAQ;AACpB,QAAI,QAAQ,EAAE,cAAc,GAAG,kBAAkB,GAAG,aAAa,EAAA;AAEjE,qBAAiB,SAAS,KAAK,YAAY,WAAW;AAAA,MACpD,OAAO,QAAQ;AAAA,MACf,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,QAAQ,MAAM;AAAA,MAClD,eAAe,CAAC,YAAY;AAAA,MAC5B,WAAW,QAAQ;AAAA,MACnB,aAAa;AAAA,IAAA,CACd,GAAG;AAEF,UAAI,MAAM,SAAS,wBAAwB;AACzC,YAAI,MAAM,SAAS;AACjB,oBAAU,MAAM;AAAA,QAClB,OAAO;AACL,qBAAW,MAAM;AAAA,QACnB;AACA,gBAAQ,MAAM,SAAS;AAAA,MACzB;AAEA,UAAI,MAAM,SAAS,gBAAgB;AACjC,YAAI,MAAM,OAAO;AACf,kBAAQ,MAAM;AAAA,QAChB;AAAA,MACF;AAAA,IACF;AAEA,WAAO,EAAE,IAAI,OAAO,SAAS,MAAA;AAAA,EAC/B;AAAA,EAEA,OAAO,gBACL,SAC4B;AAC5B,UAAM,eAAe,KAAK,yBAAyB,OAAO;AAG1D,WAAO,KAAK,YAAY,WAAW;AAAA,MACjC,OAAO,QAAQ;AAAA,MACf,UAAU,CAAC,EAAE,MAAM,QAAQ,SAAS,QAAQ,MAAM;AAAA,MAClD,eAAe,CAAC,YAAY;AAAA,MAC5B,WAAW,QAAQ;AAAA,MACnB,aAAa;AAAA,IAAA,CACd;AAAA,EACH;AAAA,EAEQ,yBAAyB,SAAuC;AACtE,QAAI,SAAS;AAEb,YAAQ,QAAQ,OAAA;AAAA,MACd,KAAK;AACH,kBAAU;AACV;AAAA,MACF,KAAK;AACH,kBAAU;AACV;AAAA,MACF,KAAK;AACH,kBAAU;AACV;AAAA,MACF;AACE,kBAAU;AAAA,IAAA;AAGd,QAAI,QAAQ,SAAS,QAAQ,MAAM,SAAS,GAAG;AAC7C,gBAAU,mCAAmC,QAAQ,MAAM,KAAK,IAAI,CAAC;AAAA,IACvE;AAEA,QAAI,QAAQ,WAAW;AACrB,gBAAU,0BAA0B,QAAQ,SAAS;AAAA,IACvD;AAEA,WAAO;AAAA,EACT;AACF;AAgBO,SAAS,sBACd,OACA,QACA,QACgC;AAChC,SAAO,IAAI,uBAAuB,EAAE,QAAQ,GAAG,OAAA,GAAU,KAAK;AAChE;AA0BO,SAAS,gBACd,OACA,QACgC;AAChC,QAAM,SAAS,uBAAA;AACf,SAAO,sBAAsB,OAAO,QAAQ,MAAM;AACpD;"}