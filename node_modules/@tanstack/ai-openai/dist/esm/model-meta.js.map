{"version":3,"file":"model-meta.js","sources":["../../src/model-meta.ts"],"sourcesContent":["import type {\n  OpenAIBaseOptions,\n  OpenAIMetadataOptions,\n  OpenAIReasoningOptions,\n  OpenAIReasoningOptionsWithConcise,\n  OpenAIStreamingOptions,\n  OpenAIStructuredOutputOptions,\n  OpenAIToolsOptions,\n} from './text/text-provider-options'\n\ninterface ModelMeta<TProviderOptions = unknown> {\n  name: string\n  supports: {\n    input: Array<'text' | 'image' | 'audio' | 'video'>\n    output: Array<'text' | 'image' | 'audio' | 'video'>\n    endpoints: Array<\n      | 'chat'\n      | 'chat-completions'\n      | 'assistants'\n      | 'speech_generation'\n      | 'image-generation'\n      | 'fine-tuning'\n      | 'batch'\n      | 'image-edit'\n      | 'moderation'\n      | 'translation'\n      | 'realtime'\n      | 'audio'\n      | 'video'\n      | 'transcription'\n    >\n    features: Array<\n      | 'streaming'\n      | 'function_calling'\n      | 'structured_outputs'\n      | 'predicted_outcomes'\n      | 'distillation'\n      | 'fine_tuning'\n    >\n    tools?: Array<\n      | 'web_search'\n      | 'file_search'\n      | 'image_generation'\n      | 'code_interpreter'\n      | 'mcp'\n      | 'computer_use'\n    >\n  }\n  context_window?: number\n  max_output_tokens?: number\n  knowledge_cutoff?: string\n  pricing: {\n    input: {\n      normal: number\n      cached?: number\n    }\n    output: {\n      normal: number\n    }\n  }\n  /**\n   * Type-level description of which provider options this model supports.\n   */\n  providerOptions?: TProviderOptions\n}\n\nconst GPT5_2 = {\n  name: 'gpt-5.2',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2025-08-31',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'distillation',\n    ],\n    tools: [\n      'web_search',\n      'file_search',\n      'image_generation',\n      'code_interpreter',\n      'mcp',\n    ],\n  },\n  pricing: {\n    input: {\n      normal: 1.75,\n      cached: 0.175,\n    },\n    output: {\n      normal: 14,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\nconst GPT5_2_PRO = {\n  name: 'gpt-5.2-pro',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2025-08-31',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: ['streaming', 'function_calling'],\n    tools: ['web_search', 'file_search', 'image_generation', 'mcp'],\n  },\n  pricing: {\n    input: {\n      normal: 21,\n    },\n    output: {\n      normal: 168,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_2_CHAT = {\n  name: 'gpt-5.2-chat-latest',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2025-08-31',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n    tools: [],\n  },\n  pricing: {\n    input: {\n      normal: 1.75,\n      cached: 0.175,\n    },\n    output: {\n      normal: 14,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\nconst GPT5_1 = {\n  name: 'gpt-5.1',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-09-30',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text', 'image'],\n    endpoints: ['chat', 'chat-completions'],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'distillation',\n    ],\n    tools: [\n      'web_search',\n      'file_search',\n      'image_generation',\n      'code_interpreter',\n      'mcp',\n    ],\n  },\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_1_CODEX = {\n  name: 'gpt-5.1-codex',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-09-30',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text', 'image'],\n    endpoints: ['chat'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n  },\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5 = {\n  name: 'gpt-5',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-09-30',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions', 'batch'],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'distillation',\n    ],\n    tools: [\n      'web_search',\n      'file_search',\n      'image_generation',\n      'code_interpreter',\n      'mcp',\n    ],\n  },\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_MINI = {\n  name: 'gpt-5-mini',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-05-31',\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions', 'batch'],\n    features: ['streaming', 'structured_outputs', 'function_calling'],\n    tools: ['web_search', 'file_search', 'mcp', 'code_interpreter'],\n  },\n  pricing: {\n    input: {\n      normal: 0.25,\n      cached: 0.025,\n    },\n    output: {\n      normal: 2,\n    },\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_NANO = {\n  name: 'gpt-5-nano',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-05-31',\n  pricing: {\n    input: {\n      normal: 0.05,\n      cached: 0.005,\n    },\n    output: {\n      normal: 0.4,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions', 'batch'],\n    features: ['streaming', 'structured_outputs', 'function_calling'],\n    tools: [\n      'web_search',\n      'file_search',\n      'mcp',\n      'image_generation',\n      'code_interpreter',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_PRO = {\n  name: 'gpt-5-pro',\n  context_window: 400_000,\n  max_output_tokens: 272_000,\n  knowledge_cutoff: '2024-09-30',\n  pricing: {\n    input: {\n      normal: 15,\n    },\n    output: {\n      normal: 120,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['streaming', 'structured_outputs', 'function_calling'],\n    tools: ['web_search', 'file_search', 'image_generation', 'mcp'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT5_CODEX = {\n  name: 'gpt-5-codex',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-09-30',\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text', 'image'],\n    endpoints: ['chat'],\n    features: ['streaming', 'structured_outputs', 'function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/**\n * Sora-2 video generation model.\n * @experimental Video generation is an experimental feature and may change.\n */\nconst SORA2 = {\n  name: 'sora-2',\n  pricing: {\n    input: {\n      normal: 0,\n    },\n    output: {\n      // per second of video\n      normal: 0.1,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['video', 'audio'],\n    endpoints: ['video'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\n/**\n * Sora-2-Pro video generation model (higher quality).\n * @experimental Video generation is an experimental feature and may change.\n */\nconst SORA2_PRO = {\n  name: 'sora-2-pro',\n  pricing: {\n    input: {\n      normal: 0,\n    },\n    output: {\n      // per second of video\n      normal: 0.5,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['video', 'audio'],\n    endpoints: ['video'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_IMAGE_1 = {\n  name: 'gpt-image-1',\n  // todo fix for images\n  pricing: {\n    input: {\n      normal: 5,\n      cached: 1.25,\n    },\n    output: {\n      normal: 0.1,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['image'],\n    endpoints: ['image-generation', 'image-edit'],\n\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_IMAGE_1_MINI = {\n  name: 'gpt-image-1-mini',\n  // todo fix for images\n  pricing: {\n    input: {\n      normal: 2,\n      cached: 0.2,\n    },\n    output: {\n      normal: 0.03,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['image'],\n    endpoints: ['image-generation', 'image-edit'],\n\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst O3_DEEP_RESEARCH = {\n  name: 'o3-deep-research',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 10,\n      cached: 2.5,\n    },\n    output: {\n      normal: 40,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst O4_MINI_DEEP_RESEARCH = {\n  name: 'o4-mini-deep-research',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 2,\n      cached: 0.5,\n    },\n    output: {\n      normal: 8,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst O3_PRO = {\n  name: 'o3-pro',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 20,\n    },\n    output: {\n      normal: 80,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['function_calling', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_AUDIO = {\n  name: 'gpt-audio',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add  audio tokens to input output\n    input: {\n      normal: 2.5,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['chat-completions'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/* const GPT_REALTIME = {\n  name: 'gpt-realtime',\n  context_window: 32_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add  audio tokens to input output\n    input: {\n      normal: 4,\n      cached: 0.5,\n    },\n    output: {\n      normal: 16,\n    },\n  },\n  supports: {\n    input: ['text', 'audio', 'image'],\n    output: ['text', 'audio'],\n    endpoints: ['realtime'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n  OpenAIToolsOptions &\n  OpenAIStreamingOptions &\n  OpenAIMetadataOptions\n>\n\nconst GPT_REALTIME_MINI = {\n  name: 'gpt-realtime-mini',\n  context_window: 32_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add  audio and image tokens to input output\n    input: {\n      normal: 0.6,\n      cached: 0.06,\n    },\n    output: {\n      normal: 2.4,\n    },\n  },\n  supports: {\n    input: ['text', 'audio', 'image'],\n    output: ['text', 'audio'],\n    endpoints: ['realtime'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n  OpenAIToolsOptions &\n  OpenAIStreamingOptions &\n  OpenAIMetadataOptions\n> */\n\nconst GPT_AUDIO_MINI = {\n  name: 'gpt-audio-mini',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add  audio tokens to input output\n    input: {\n      normal: 0.6,\n    },\n    output: {\n      normal: 2.4,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['chat-completions'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst O3 = {\n  name: 'o3',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 2,\n      cached: 0.5,\n    },\n    output: {\n      normal: 8,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch', 'chat-completions'],\n    features: ['function_calling', 'structured_outputs', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst O4_MINI = {\n  name: 'o4-mini',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 1.1,\n      cached: 0.275,\n    },\n    output: {\n      normal: 4.4,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch', 'chat-completions', 'fine-tuning'],\n    features: [\n      'function_calling',\n      'structured_outputs',\n      'streaming',\n      'fine_tuning',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT4_1 = {\n  name: 'gpt-4.1',\n  context_window: 1_047_576,\n  max_output_tokens: 32_768,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 2,\n      cached: 0.5,\n    },\n    output: {\n      normal: 8,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'assistants',\n      'fine-tuning',\n      'batch',\n    ],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'distillation',\n      'fine_tuning',\n    ],\n    tools: [\n      'web_search',\n      'file_search',\n      'image_generation',\n      'code_interpreter',\n      'mcp',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT4_1_MINI = {\n  name: 'gpt-4.1-mini',\n  context_window: 1_047_576,\n  max_output_tokens: 32_768,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 0.4,\n      cached: 0.1,\n    },\n    output: {\n      normal: 1.6,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'assistants',\n      'fine-tuning',\n      'batch',\n    ],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'fine_tuning',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT4_1_NANO = {\n  name: 'gpt-4.1-nano',\n  context_window: 1_047_576,\n  max_output_tokens: 32_768,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    input: {\n      normal: 0.1,\n      cached: 0.025,\n    },\n    output: {\n      normal: 0.4,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'assistants',\n      'fine-tuning',\n      'batch',\n    ],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'fine_tuning',\n      'predicted_outcomes',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst O1_PRO = {\n  name: 'o1-pro',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 150,\n    },\n    output: {\n      normal: 600,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['function_calling', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst COMPUTER_USE_PREVIEW = {\n  name: 'computer-use-preview',\n  context_window: 8_192,\n  max_output_tokens: 1_024,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 3,\n    },\n    output: {\n      normal: 12,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptionsWithConcise &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_4O_MINI_SEARCH_PREVIEW = {\n  name: 'gpt-4o-mini-search-preview',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 0.15,\n    },\n    output: {\n      normal: 0.6,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    endpoints: ['chat-completions'],\n    features: ['streaming', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_4O_SEARCH_PREVIEW = {\n  name: 'gpt-4o-search-preview',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 2.5,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    endpoints: ['chat-completions'],\n    features: ['streaming', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst O3_MINI = {\n  name: 'o3-mini',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 1.1,\n      cached: 0.55,\n    },\n    output: {\n      normal: 4.4,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    endpoints: ['chat', 'batch', 'chat-completions', 'assistants'],\n    features: ['function_calling', 'structured_outputs', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_4O_MINI_AUDIO = {\n  name: 'gpt-4o-mini-audio',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 0.15,\n    },\n    output: {\n      normal: 0.6,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['chat-completions'],\n    features: ['function_calling', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/* const GPT_4O_MINI_REALTIME = {\n  name: 'gpt-4o-mini-realtime',\n  context_window: 16_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add audio tokens\n    input: {\n      normal: 0.6,\n      cached: 0.3,\n    },\n    output: {\n      normal: 2.4,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['realtime'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n  OpenAIToolsOptions &\n  OpenAIStreamingOptions &\n  OpenAIMetadataOptions\n>\n */\nconst O1 = {\n  name: 'o1',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 15,\n      cached: 7.5,\n    },\n    output: {\n      normal: 60,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'batch', 'chat-completions', 'assistants'],\n    features: ['function_calling', 'structured_outputs', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/* const OMNI_MODERATION = {\n  name: 'omni-moderation',\n  pricing: {\n    input: {\n      normal: 0,\n    },\n    output: {\n      normal: 0,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['batch', 'moderation'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n> */\n\nconst GPT_4O = {\n  name: 'gpt-4o',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 2.5,\n      cached: 1.25,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'assistants',\n      'fine-tuning',\n      'batch',\n    ],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'distillation',\n      'fine_tuning',\n      'predicted_outcomes',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_4O_AUDIO = {\n  name: 'gpt-4o-audio',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 2.5,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['chat-completions'],\n    features: ['streaming', 'function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_4O_MINI = {\n  name: 'gpt-4o-mini',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 0.15,\n      cached: 0.075,\n    },\n    output: {\n      normal: 0.6,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'assistants',\n      'fine-tuning',\n      'batch',\n    ],\n    features: [\n      'streaming',\n      'function_calling',\n      'structured_outputs',\n      'fine_tuning',\n      'predicted_outcomes',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/* const GPT__4O_REALTIME = {\n  name: 'gpt-4o-realtime',\n  context_window: 32_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    // todo add  audio tokens to input output\n    input: {\n      normal: 5,\n      cached: 2.5,\n    },\n    output: {\n      normal: 20,\n    },\n  },\n  supports: {\n    input: ['text', 'audio'],\n    output: ['text', 'audio'],\n    endpoints: ['realtime'],\n    features: ['function_calling'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n  OpenAIToolsOptions &\n  OpenAIStreamingOptions &\n  OpenAIMetadataOptions\n> */\n\nconst GPT_4_TURBO = {\n  name: 'gpt-4-turbo',\n  context_window: 128_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-12-01',\n  pricing: {\n    input: {\n      normal: 10,\n    },\n    output: {\n      normal: 30,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions', 'assistants', 'batch'],\n    features: ['function_calling', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst CHATGPT_40 = {\n  name: 'chatgpt-4o-latest',\n  context_window: 128_000,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2023-10-01',\n  pricing: {\n    input: {\n      normal: 5,\n    },\n    output: {\n      normal: 15,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: ['predicted_outcomes', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_5_1_CODEX_MINI = {\n  name: 'gpt-5.1-codex-mini',\n  context_window: 400_000,\n  max_output_tokens: 128_000,\n  knowledge_cutoff: '2024-09-30',\n  pricing: {\n    input: {\n      normal: 0.25,\n      cached: 0.025,\n    },\n    output: {\n      normal: 2,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text', 'image'],\n    endpoints: ['chat'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst CODEX_MINI_LATEST = {\n  name: 'codex-mini-latest',\n  context_window: 200_000,\n  max_output_tokens: 100_000,\n  knowledge_cutoff: '2024-06-01',\n  pricing: {\n    input: {\n      normal: 1.5,\n      cached: 0.375,\n    },\n    output: {\n      normal: 6,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst DALL_E_2 = {\n  name: 'dall-e-2',\n  pricing: {\n    // todo image tokens\n    input: {\n      normal: 0.016,\n    },\n    output: {\n      normal: 0.02,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['image'],\n    endpoints: ['image-generation', 'image-edit'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst DALL_E_3 = {\n  name: 'dall-e-3',\n  pricing: {\n    // todo image tokens\n    input: {\n      normal: 0.04,\n    },\n    output: {\n      normal: 0.08,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['image'],\n    endpoints: ['image-generation', 'image-edit'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_3_5_TURBO = {\n  name: 'gpt-3.5-turbo',\n  context_window: 16_385,\n  max_output_tokens: 4_096,\n  knowledge_cutoff: '2021-09-01',\n  pricing: {\n    input: {\n      normal: 0.5,\n    },\n    output: {\n      normal: 1.5,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions', 'batch', 'fine-tuning'],\n    features: ['fine_tuning'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_4 = {\n  name: 'gpt-4',\n  context_window: 8_192,\n  max_output_tokens: 8_192,\n  knowledge_cutoff: '2023-12-01',\n  pricing: {\n    input: {\n      normal: 30,\n    },\n    output: {\n      normal: 60,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['text'],\n    endpoints: [\n      'chat',\n      'chat-completions',\n      'batch',\n      'fine-tuning',\n      'assistants',\n    ],\n    features: ['fine_tuning', 'streaming'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n/* \nconst GPT_4O_MINI_TRANSCRIBE = {\n  name: 'gpt-4o-mini-transcribe',\n  context_window: 16_000,\n  max_output_tokens: 2_000,\n  knowledge_cutoff: '2024-01-01',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 1.25,\n    },\n    output: {\n      normal: 5,\n    },\n  },\n  supports: {\n    input: ['audio', 'text'],\n    output: ['text'],\n    endpoints: ['realtime', 'transcription'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_4O_MINI_TTS = {\n  name: 'gpt-4o-mini-tts',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 0.6,\n    },\n    output: {\n      normal: 12,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['audio'],\n    endpoints: ['speech_generation'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst GPT_4O_TRANSCRIBE = {\n  name: 'gpt-4o-transcribe',\n  context_window: 16_000,\n  max_output_tokens: 2_000,\n  knowledge_cutoff: '2024-06-01',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 2.5,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['audio', 'text'],\n    output: ['text'],\n    endpoints: ['realtime', 'transcription'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n> */\n/* \nconst GPT_4O_TRANSCRIBE_DIARIZE = {\n  name: 'gpt-4o-transcribe-diarize',\n  context_window: 16_000,\n  max_output_tokens: 2_000,\n  knowledge_cutoff: '2024-06-01',\n  pricing: {\n    // todo audio tokens\n    input: {\n      normal: 2.5,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['audio', 'text'],\n    output: ['text'],\n    endpoints: ['transcription'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n> */\n\nconst GPT_5_1_CHAT = {\n  name: 'gpt-5.1-chat-latest',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2024-09-30',\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\nconst GPT_5_CHAT = {\n  name: 'gpt-5-chat-latest',\n  context_window: 128_000,\n  max_output_tokens: 16_384,\n  knowledge_cutoff: '2024-09-30',\n  pricing: {\n    input: {\n      normal: 1.25,\n      cached: 0.125,\n    },\n    output: {\n      normal: 10,\n    },\n  },\n  supports: {\n    input: ['text', 'image'],\n    output: ['text'],\n    endpoints: ['chat', 'chat-completions'],\n    features: ['streaming', 'function_calling', 'structured_outputs'],\n    tools: [\n      'web_search',\n      'file_search',\n      'image_generation',\n      'code_interpreter',\n      'mcp',\n    ],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n>\n\n/* const TTS_1 = {\n  name: 'tts-1',\n  pricing: {\n    // todo figure out pricing\n    input: {\n      normal: 15,\n    },\n    output: {\n      normal: 15,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['audio'],\n    endpoints: ['speech_generation'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n>\n\nconst TTS_1_HD = {\n  name: 'tts-1-hd',\n  pricing: {\n    // todo figure out pricing\n    input: {\n      normal: 30,\n    },\n    output: {\n      normal: 30,\n    },\n  },\n  supports: {\n    input: ['text'],\n    output: ['audio'],\n    endpoints: ['speech_generation'],\n    features: [],\n  },\n} as const satisfies ModelMeta<\n  OpenAIBaseOptions & OpenAIStreamingOptions & OpenAIMetadataOptions\n> */\n\n// Chat/text completion models (based on endpoints: \"chat\" or \"chat-completions\")\nexport const OPENAI_CHAT_MODELS = [\n  // Frontier models\n  GPT5_2.name,\n  GPT5_2_PRO.name,\n  GPT5_2_CHAT.name,\n  GPT5_1.name,\n  GPT5_1_CODEX.name,\n  GPT5.name,\n  GPT5_MINI.name,\n  GPT5_NANO.name,\n  GPT5_PRO.name,\n  GPT5_CODEX.name,\n  // Reasoning models\n  O3.name,\n  O3_PRO.name,\n  O3_MINI.name,\n  O4_MINI.name,\n  O3_DEEP_RESEARCH.name,\n  O4_MINI_DEEP_RESEARCH.name,\n  // GPT-4 series\n  GPT4_1.name,\n  GPT4_1_MINI.name,\n  GPT4_1_NANO.name,\n  GPT_4.name,\n  GPT_4_TURBO.name,\n  GPT_4O.name,\n  GPT_4O_MINI.name,\n  // GPT-3.5\n  GPT_3_5_TURBO.name,\n  // Audio-enabled chat models\n  GPT_AUDIO.name,\n  GPT_AUDIO_MINI.name,\n  GPT_4O_AUDIO.name,\n  GPT_4O_MINI_AUDIO.name,\n  // ChatGPT models\n  GPT_5_1_CHAT.name,\n  GPT_5_CHAT.name,\n  CHATGPT_40.name,\n  // Specialized\n  GPT_5_1_CODEX_MINI.name,\n  CODEX_MINI_LATEST.name,\n  // Preview models\n  GPT_4O_SEARCH_PREVIEW.name,\n  GPT_4O_MINI_SEARCH_PREVIEW.name,\n  COMPUTER_USE_PREVIEW.name,\n  // Legacy reasoning\n  O1.name,\n  O1_PRO.name,\n] as const\n\nexport type OpenAIChatModel = (typeof OPENAI_CHAT_MODELS)[number]\n\n// Image generation models (based on endpoints: \"image-generation\" or \"image-edit\")\nexport const OPENAI_IMAGE_MODELS = [\n  GPT_IMAGE_1.name,\n  GPT_IMAGE_1_MINI.name,\n  DALL_E_3.name,\n  DALL_E_2.name,\n] as const\n\nexport type OpenAIImageModel = (typeof OPENAI_IMAGE_MODELS)[number]\n\n// Audio models (based on endpoints: \"transcription\", \"speech_generation\", or \"realtime\")\n/* const OPENAI_AUDIO_MODELS = [\n  // Transcription models\n  GPT_4O_TRANSCRIBE.name,\n  GPT_4O_TRANSCRIBE_DIARIZE.name,\n  GPT_4O_MINI_TRANSCRIBE.name,\n  // Realtime models\n  GPT_REALTIME.name,\n  GPT_REALTIME_MINI.name,\n  GPT__4O_REALTIME.name,\n  GPT_4O_MINI_REALTIME.name,\n  // Text-to-speech models\n  GPT_4O_MINI_TTS.name,\n  TTS_1.name,\n  TTS_1_HD.name,\n] as const */\n\n// Transcription-only models (based on endpoints: \"transcription\")\n/* const OPENAI_TRANSCRIPTION_MODELS = [\n  GPT_4O_TRANSCRIBE.name,\n  GPT_4O_TRANSCRIBE_DIARIZE.name,\n  GPT_4O_MINI_TRANSCRIBE.name,\n] as const\n\n/**\n * Video generation models (based on endpoints: \"video\")\n * @experimental Video generation is an experimental feature and may change.\n */\nexport const OPENAI_VIDEO_MODELS = [SORA2.name, SORA2_PRO.name] as const\n\nexport type OpenAIVideoModel = (typeof OPENAI_VIDEO_MODELS)[number]\n\n/**\n * Text-to-speech models (based on endpoints: \"speech_generation\")\n */\nexport const OPENAI_TTS_MODELS = [\n  'tts-1',\n  'tts-1-hd',\n  'gpt-4o-audio-preview',\n] as const\n\nexport type OpenAITTSModel = (typeof OPENAI_TTS_MODELS)[number]\n\n/**\n * Transcription models (based on endpoints: \"transcription\")\n */\nexport const OPENAI_TRANSCRIPTION_MODELS = [\n  'whisper-1',\n  'gpt-4o-transcribe',\n  'gpt-4o-mini-transcribe',\n  'gpt-4o-transcribe-diarize',\n] as const\n\nexport type OpenAITranscriptionModel =\n  (typeof OPENAI_TRANSCRIPTION_MODELS)[number]\n\n/**\n * Type-only map from chat model name to its provider options type.\n * Used by the core AI types (via the adapter) to narrow\n * `providerOptions` based on the selected model.\n *\n * Manually defined to ensure accurate type narrowing per model.\n */\nexport type OpenAIChatModelProviderOptionsByName = {\n  [GPT5_2.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_2_CHAT.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_2_PRO.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_1.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_1_CODEX.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_MINI.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_NANO.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_PRO.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT5_CODEX.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT4_1.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT4_1_MINI.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT4_1_NANO.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4O.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4O_MINI.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n\n  // Models WITHOUT structured output support (NO 'text' field)\n  [GPT_4.name]: OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4_TURBO.name]: OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_3_5_TURBO.name]: OpenAIBaseOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [CHATGPT_40.name]: OpenAIBaseOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [O3.name]: OpenAIBaseOptions & OpenAIReasoningOptions & OpenAIMetadataOptions\n  [O3_PRO.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n  [O3_MINI.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n  [O4_MINI.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n  [O3_DEEP_RESEARCH.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n  [O4_MINI_DEEP_RESEARCH.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n  [O1.name]: OpenAIBaseOptions & OpenAIReasoningOptions & OpenAIMetadataOptions\n  [O1_PRO.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIMetadataOptions\n\n  // Audio models\n  [GPT_AUDIO.name]: OpenAIBaseOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_AUDIO_MINI.name]: OpenAIBaseOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4O_AUDIO.name]: OpenAIBaseOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4O_MINI_AUDIO.name]: OpenAIBaseOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n\n  // Chat-only models\n  [GPT_5_1_CHAT.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIMetadataOptions\n  [GPT_5_CHAT.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIMetadataOptions\n\n  // Codex models\n  [GPT_5_1_CODEX_MINI.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [CODEX_MINI_LATEST.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n\n  // Search models\n  [GPT_4O_SEARCH_PREVIEW.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n  [GPT_4O_MINI_SEARCH_PREVIEW.name]: OpenAIBaseOptions &\n    OpenAIStructuredOutputOptions &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n\n  // Special models\n  [COMPUTER_USE_PREVIEW.name]: OpenAIBaseOptions &\n    OpenAIReasoningOptionsWithConcise &\n    OpenAIToolsOptions &\n    OpenAIStreamingOptions &\n    OpenAIMetadataOptions\n}\n\n/**\n * Type-only map from chat model name to its supported input modalities.\n * Based on the 'supports.input' arrays defined for each model.\n * Used by the core AI types to constrain ContentPart types based on the selected model.\n * Note: These must be inlined as readonly arrays (not typeof) because the model\n * constants are not exported and typeof references don't work in .d.ts files\n * when consumed by external packages.\n */\nexport type OpenAIModelInputModalitiesByName = {\n  [GPT5_2.name]: typeof GPT5_2.supports.input\n  [GPT5_2_PRO.name]: typeof GPT5_2_PRO.supports.input\n  [GPT5_2_CHAT.name]: typeof GPT5_2_CHAT.supports.input\n  // Models with text + image input\n  [GPT5_1.name]: typeof GPT5_1.supports.input\n  [GPT5_1_CODEX.name]: typeof GPT5_1_CODEX.supports.input\n  [GPT5.name]: typeof GPT5.supports.input\n  [GPT5_MINI.name]: typeof GPT5_MINI.supports.input\n  [GPT5_NANO.name]: typeof GPT5_NANO.supports.input\n  [GPT5_PRO.name]: typeof GPT5_PRO.supports.input\n  [GPT5_CODEX.name]: typeof GPT5_CODEX.supports.input\n  [GPT4_1.name]: typeof GPT4_1.supports.input\n  [GPT4_1_MINI.name]: typeof GPT4_1_MINI.supports.input\n  [GPT4_1_NANO.name]: typeof GPT4_1_NANO.supports.input\n\n  [GPT_4O.name]: typeof GPT_4O.supports.input\n  [GPT_4O_MINI.name]: typeof GPT_4O_MINI.supports.input\n  [GPT_4_TURBO.name]: typeof GPT_4_TURBO.supports.input\n  [CHATGPT_40.name]: typeof CHATGPT_40.supports.input\n  [GPT_5_1_CHAT.name]: typeof GPT_5_1_CHAT.supports.input\n  [GPT_5_CHAT.name]: typeof GPT_5_CHAT.supports.input\n  [GPT_5_1_CODEX_MINI.name]: typeof GPT_5_1_CODEX_MINI.supports.input\n  [CODEX_MINI_LATEST.name]: typeof CODEX_MINI_LATEST.supports.input\n  [COMPUTER_USE_PREVIEW.name]: typeof COMPUTER_USE_PREVIEW.supports.input\n  [O3.name]: typeof O3.supports.input\n  [O3_PRO.name]: typeof O3_PRO.supports.input\n  [O3_DEEP_RESEARCH.name]: typeof O3_DEEP_RESEARCH.supports.input\n  [O4_MINI_DEEP_RESEARCH.name]: typeof O4_MINI_DEEP_RESEARCH.supports.input\n  [O4_MINI.name]: typeof O4_MINI.supports.input\n  [O1.name]: typeof O1.supports.input\n  [O1_PRO.name]: typeof O1_PRO.supports.input\n\n  // Models with text + audio input\n  [GPT_AUDIO.name]: typeof GPT_AUDIO.supports.input\n  [GPT_AUDIO_MINI.name]: typeof GPT_AUDIO_MINI.supports.input\n  [GPT_4O_AUDIO.name]: typeof GPT_4O_AUDIO.supports.input\n  [GPT_4O_MINI_AUDIO.name]: typeof GPT_4O_MINI_AUDIO.supports.input\n\n  // Text-only models\n  [GPT_4.name]: typeof GPT_4.supports.input\n  [GPT_3_5_TURBO.name]: typeof GPT_3_5_TURBO.supports.input\n  [O3_MINI.name]: typeof O3_MINI.supports.input\n  [GPT_4O_SEARCH_PREVIEW.name]: typeof GPT_4O_SEARCH_PREVIEW.supports.input\n  [GPT_4O_MINI_SEARCH_PREVIEW.name]: typeof GPT_4O_MINI_SEARCH_PREVIEW.supports.input\n}\n"],"names":[],"mappings":"AAkEA,MAAM,SAAS;AAAA,EACb,MAAM;AA+BR;AAQA,MAAM,aAAa;AAAA,EACjB,MAAM;AAmBR;AAQA,MAAM,cAAc;AAAA,EAClB,MAAM;AAoBR;AAQA,MAAM,SAAS;AAAA,EACb,MAAM;AA+BR;AASA,MAAM,eAAe;AAAA,EACnB,MAAM;AAmBR;AASA,MAAM,OAAO;AAAA,EACX,MAAM;AA+BR;AASA,MAAM,YAAY;AAAA,EAChB,MAAM;AAoBR;AASA,MAAM,YAAY;AAAA,EAChB,MAAM;AA0BR;AASA,MAAM,WAAW;AAAA,EACf,MAAM;AAmBR;AASA,MAAM,aAAa;AAAA,EACjB,MAAM;AAmBR;AAaA,MAAM,QAAQ;AAAA,EACZ,MAAM;AAgBR;AAQA,MAAM,YAAY;AAAA,EAChB,MAAM;AAgBR;AAIA,MAAM,cAAc;AAAA,EAClB,MAAM;AAkBR;AAIA,MAAM,mBAAmB;AAAA,EACvB,MAAM;AAkBR;AAIA,MAAM,mBAAmB;AAAA,EACvB,MAAM;AAmBR;AAOA,MAAM,wBAAwB;AAAA,EAC5B,MAAM;AAmBR;AAOA,MAAM,SAAS;AAAA,EACb,MAAM;AAkBR;AASA,MAAM,YAAY;AAAA,EAChB,MAAM;AAmBR;AA+DA,MAAM,iBAAiB;AAAA,EACrB,MAAM;AAmBR;AAOA,MAAM,KAAK;AAAA,EACT,MAAM;AAmBR;AASA,MAAM,UAAU;AAAA,EACd,MAAM;AAwBR;AAQA,MAAM,SAAS;AAAA,EACb,MAAM;AAsCR;AASA,MAAM,cAAc;AAAA,EAClB,MAAM;AA8BR;AAQA,MAAM,cAAc;AAAA,EAClB,MAAM;AA+BR;AAQA,MAAM,SAAS;AAAA,EACb,MAAM;AAkBR;AASA,MAAM,uBAAuB;AAAA,EAC3B,MAAM;AAkBR;AAQA,MAAM,6BAA6B;AAAA,EACjC,MAAM;AAkBR;AAIA,MAAM,wBAAwB;AAAA,EAC5B,MAAM;AAkBR;AAIA,MAAM,UAAU;AAAA,EACd,MAAM;AAmBR;AASA,MAAM,oBAAoB;AAAA,EACxB,MAAM;AAmBR;AAmCA,MAAM,KAAK;AAAA,EACT,MAAM;AAmBR;AA6BA,MAAM,SAAS;AAAA,EACb,MAAM;AAgCR;AASA,MAAM,eAAe;AAAA,EACnB,MAAM;AAmBR;AAOA,MAAM,cAAc;AAAA,EAClB,MAAM;AA+BR;AAoCA,MAAM,cAAc;AAAA,EAClB,MAAM;AAkBR;AAOA,MAAM,aAAa;AAAA,EACjB,MAAM;AAkBR;AAIA,MAAM,qBAAqB;AAAA,EACzB,MAAM;AAmBR;AASA,MAAM,oBAAoB;AAAA,EACxB,MAAM;AAmBR;AASA,MAAM,WAAW;AAAA,EACf,MAAM;AAgBR;AAIA,MAAM,WAAW;AAAA,EACf,MAAM;AAgBR;AAIA,MAAM,gBAAgB;AAAA,EACpB,MAAM;AAkBR;AAIA,MAAM,QAAQ;AAAA,EACZ,MAAM;AAwBR;AAiGA,MAAM,eAAe;AAAA,EACnB,MAAM;AAmBR;AASA,MAAM,aAAa;AAAA,EACjB,MAAM;AA0BR;AAoDO,MAAM,qBAAqB;AAAA;AAAA,EAEhC,OAAO;AAAA,EACP,WAAW;AAAA,EACX,YAAY;AAAA,EACZ,OAAO;AAAA,EACP,aAAa;AAAA,EACb,KAAK;AAAA,EACL,UAAU;AAAA,EACV,UAAU;AAAA,EACV,SAAS;AAAA,EACT,WAAW;AAAA;AAAA,EAEX,GAAG;AAAA,EACH,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR,iBAAiB;AAAA,EACjB,sBAAsB;AAAA;AAAA,EAEtB,OAAO;AAAA,EACP,YAAY;AAAA,EACZ,YAAY;AAAA,EACZ,MAAM;AAAA,EACN,YAAY;AAAA,EACZ,OAAO;AAAA,EACP,YAAY;AAAA;AAAA,EAEZ,cAAc;AAAA;AAAA,EAEd,UAAU;AAAA,EACV,eAAe;AAAA,EACf,aAAa;AAAA,EACb,kBAAkB;AAAA;AAAA,EAElB,aAAa;AAAA,EACb,WAAW;AAAA,EACX,WAAW;AAAA;AAAA,EAEX,mBAAmB;AAAA,EACnB,kBAAkB;AAAA;AAAA,EAElB,sBAAsB;AAAA,EACtB,2BAA2B;AAAA,EAC3B,qBAAqB;AAAA;AAAA,EAErB,GAAG;AAAA,EACH,OAAO;AACT;AAKO,MAAM,sBAAsB;AAAA,EACjC,YAAY;AAAA,EACZ,iBAAiB;AAAA,EACjB,SAAS;AAAA,EACT,SAAS;AACX;AAgCO,MAAM,sBAAsB,CAAC,MAAM,MAAM,UAAU,IAAI;AAOvD,MAAM,oBAAoB;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AACF;AAOO,MAAM,8BAA8B;AAAA,EACzC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;"}